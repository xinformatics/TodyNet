{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9fc933-5024-468d-91bd-6408aa8297b9",
   "metadata": {},
   "source": [
    "![alt text](04_respiratory_metrics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a02078-96b3-4f14-9669-fb49f4edb4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be49837-23e5-418a-a1f6-aa834f8bb18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from loader import ICUVariableLengthLoaderTables, ICUVariableLengthDataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289ba758-e261-48fa-ac80-f8d81e62fce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'NVIDIA GeForce RTX 4060 Ti')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.is_available(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e40d61-adfc-430c-96e2-0a205a366cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c014230b-cda3-4cbc-920a-2d5b16570858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from net_dev import GNNStack\n",
    "# from utils_todynet_binary import AverageMeter, accuracy, log_msg, get_default_train_val_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5d7406-8f67-45bd-add7-cb4a8fe7a97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a458334-b4e5-4c9b-bacb-976cb10ec9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=None, gamma=2):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         loss = (self.alpha[targets] * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "#         return loss\n",
    "\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=None, gamma=2, num_classes=None):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.gamma = gamma\n",
    "#         if alpha is None:\n",
    "#             self.alpha = None\n",
    "#         else:\n",
    "#             # If alpha is a single float number, expand it to a tensor\n",
    "#             if isinstance(alpha, float):\n",
    "#                 assert num_classes is not None, \"num_classes must be specified when alpha is a single float\"\n",
    "#                 self.alpha = torch.full((num_classes,), alpha)\n",
    "#             else:\n",
    "#                 self.alpha = alpha\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         if self.alpha is not None:\n",
    "#             if self.alpha.type() != inputs.data.type():\n",
    "#                 self.alpha = self.alpha.type_as(inputs.data)\n",
    "#             at = self.alpha[targets]\n",
    "#         else:\n",
    "#             at = 1.0\n",
    "#         loss = (at * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b608f5b7-259a-4fea-be59-b90be979c3b9",
   "metadata": {},
   "source": [
    "## aruguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e2de2d-8c0d-4ab8-8090-5e5621f13034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'arch': 'dyGIN2d', #what other models I can put here?? dyGCN2d, dyGIN2d\n",
    "    'dataset': 'Resp_failure_development_attentionMSE', # \"AtrialFibrillation\" # 'Mortality', # 'MIMIC3' Resp_failure\n",
    "    'num_layers': 2,  # the number of GNN layers  3\n",
    "    'groups': 32,  # the number of time series groups (num_graphs)\n",
    "    'pool_ratio': 0.0,  # the ratio of pooling for nodes # initially 0.1 but changed to 0 because the node number was decreasing\n",
    "    'kern_size': [3,3],  # list of time conv kernel size for each layer [9,5,3]\n",
    "    'in_dim': 64,  # input dimensions of GNN stacks\n",
    "    'hidden_dim': 64,  # hidden dimensions of GNN stacks\n",
    "    'out_dim': 64,  # output dimensions of GNN stacks\n",
    "    'workers': 0,  # number of data loading workers\n",
    "    'epochs': 20,  # number of total epochs to run\n",
    "    'batch_size': 8,  # mini-batch size, this is the total batch size of all GPUs\n",
    "    'val_batch_size': 8,  # validation batch size\n",
    "    'lr': 0.0002,  # initial learning rate\n",
    "    'weight_decay': 1e-4,  # weight decay\n",
    "    'evaluate': False,  # evaluate model on validation set\n",
    "    'seed': 3,  # seed for initializing training\n",
    "    'gpu': 0,  # GPU id to use\n",
    "    'use_benchmark': True,  # use benchmark\n",
    "    'tag': 'date',  # the tag for identifying the log and model files\n",
    "    'loss':'bce',\n",
    "    'resample':'5min',\n",
    "    'series_length':864,\n",
    "}\n",
    "\n",
    "# resample works: 5min, 15 min, 35 min, 45min. analysis will have 5,15,45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8334a7f-fd2c-4bbf-ab0e-826642283b1e",
   "metadata": {},
   "source": [
    "### GPU 2 is used to training in sheet 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584106be-b4fa-4cad-80b0-8f66ad715837",
   "metadata": {},
   "source": [
    "### TODO\n",
    "## Molly douglas has filtered 116 features from 231, ~50% reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "982150c8-5c87-471b-b810-75f52df10c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"mortality\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config=args\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c31c8a0-dcb1-4e0c-b44e-36bb9bd8f4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = TensorDataset(data_train, label_train)\n",
    "# val_dataset   = TensorDataset(data_val, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f6c801-7a9f-4f8a-9cbf-362febcf0683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=args['batch_size'],shuffle=True, num_workers=args['workers'], pin_memory=True)\n",
    "# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args['val_batch_size'], shuffle=False,num_workers=args['workers'],pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a648e31-70d5-4f32-b03a-6fd95b5211e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     # args = parser.parse_args()\n",
    "    \n",
    "#     # args.kern_size = [ int(l) for l in args.kern_size.split(\",\") ]\n",
    "\n",
    "#     # if args.seed is not None:\n",
    "#     random.seed(args['seed'])\n",
    "#     torch.manual_seed(args['seed'])\n",
    "\n",
    "#     main_work(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4c9a44f-2214-47c8-8de8-d47d7ba5202d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "              \n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        \n",
    "        # print(output, target)\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            try:\n",
    "                res.append(correct_k.mul_(100.0 / batch_size))\n",
    "            except:\n",
    "                res.append(0)\n",
    "\n",
    "        return res\n",
    "\n",
    "def log_msg(message, log_file):\n",
    "    with open(log_file, 'a') as f:\n",
    "        print(message, file=f)\n",
    "\n",
    "\n",
    "def get_default_train_val_test_loader(args):\n",
    "\n",
    "    # get dataset-id\n",
    "    dsid = args['dataset']\n",
    "    h5_path= 'h5_folder/ml_stage_12h.h5'\n",
    "    # get dataset from .pt\n",
    "    # data_train  = torch.load(f'data/UCR/{dsid}/X_train.pt')\n",
    "    # data_val    = torch.load(f'data/UCR/{dsid}/X_valid.pt')\n",
    "    # data_val    = torch.load(f'data/UCR/{dsid}/X_test.pt')\n",
    "    \n",
    "    # label_train = torch.load(f'data/UCR/{dsid}/y_train.pt')\n",
    "    # label_val   = torch.load(f'data/UCR/{dsid}/y_valid.pt')\n",
    "    # label_val   = torch.load(f'data/UCR/{dsid}/y_test.pt')\n",
    "\n",
    "    # label_train = label_train.flatten().to(dtype=torch.int64)\n",
    "    # label_val   = label_val.flatten().to(dtype=torch.int64)\n",
    "    # init [num_variables, seq_length, num_classes]\n",
    "    \n",
    "    num_nodes = 231\n",
    "    seq_length = 864 #288 #2016 ### now we will reduce the sequence length to see the performance in short-range\n",
    "    num_classes = 2\n",
    "\n",
    "\n",
    "    # convert data & labels to TensorDataset\n",
    "    # train_dataset = TensorDataset(data_train, label_train)\n",
    "    # val_dataset = TensorDataset(data_val, label_val)\n",
    "    \n",
    "#     task              = 'Mortality_At24Hours'\n",
    "#     maxlen            = 288                                                                             #patients| pos  | neg |\n",
    "#     data_loader_train = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='train') #10524   | 9613 | 911 |\n",
    "#     data_loader_val   = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='val')   #2205    | 2048 | 157 |\n",
    "#     data_loader_test  = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='test')  #2231    | 2045 | 186 |\n",
    "    \n",
    "    \n",
    "    \n",
    "    task   = 'Dynamic_RespFailure_12Hours' ##27249\n",
    "    maxlen            = 864 #288 #2016                                                                         #|patients|    #-1 =8065                    #2016                      #difference\n",
    "    data_loader_train = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='train') #| 19092  |    5646423(3467116+2179307)     4776429(2901908+1874521)   869994(565208+304786)\n",
    "    data_loader_val   = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='val')   #| 4081   |    1220285(758822+461463)       1006329(614326+392003)     213956(144496+69460)\n",
    "    data_loader_test  = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='test')  #| 4076   |    1209724(753935+455789)       1015139(620532+394607)     194585(133403+61182)\n",
    "    \n",
    "    train_loader = DataLoader(data_loader_train, batch_size=4, shuffle=True, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "    val_loader   = DataLoader(data_loader_val,   batch_size=4, shuffle=False, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "    # val_loader  = DataLoader(data_loader_test,  batch_size=4, shuffle=False, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "    test_loader  = DataLoader(data_loader_test,  batch_size=4, shuffle=False, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "\n",
    "\n",
    "    # data_loader\n",
    "    # train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=args['batch_size'],shuffle=True,num_workers=args['workers'], pin_memory=True)\n",
    "    # val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=args['val_batch_size'],shuffle=False,num_workers=args['workers'],pin_memory=True)\n",
    "\n",
    "\n",
    "    return train_loader, val_loader, test_loader, num_nodes, seq_length, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "991c1bc0-5e2d-4ea2-9691-3e2fac259bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main_work(args):\n",
    "    \n",
    "    random.seed(args['seed'])\n",
    "    torch.manual_seed(args['seed'])\n",
    "    \n",
    "    \n",
    "    # init metrics\n",
    "    best_acc1 = 0\n",
    "    best_roc  = 0\n",
    "    best_pr   = 0\n",
    "    best_f1   = 0\n",
    "    best_mcc  = 0\n",
    "    \n",
    "    best_test_acc1 = 0\n",
    "    best_test_roc  = 0\n",
    "    best_test_pr   = 0\n",
    "    best_test_f1   = 0\n",
    "    best_test_mcc  = 0    \n",
    "    \n",
    "    if args['tag'] == 'date':\n",
    "        local_date = time.strftime('%m.%d %H:%M', time.localtime(time.time()))\n",
    "        args['tag'] = local_date\n",
    "        \n",
    "    # Use the 'tag' which now contains either the date or a custom tag along with the dataset name for the directory\n",
    "    run_dir_name = f\"{args['dataset']}_{args['tag']}\"\n",
    "   \n",
    "    # Base directory for saving models\n",
    "    base_model_save_dir = \"saved_models\"\n",
    "   \n",
    "    # Specific directory for this run\n",
    "    specific_model_save_dir = os.path.join(base_model_save_dir, run_dir_name)\n",
    "    os.makedirs(specific_model_save_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Models will be saved in: {specific_model_save_dir}\")        \n",
    "\n",
    "\n",
    "    log_file = 'log/{}_gpu{}_{}_{}_exp.txt'.format(args['tag'], args['gpu'], args['arch'], args['dataset'])\n",
    "    \n",
    "    \n",
    "    if args['gpu'] is not None:\n",
    "        print(\"Use GPU: {} for training\".format(args['gpu']))\n",
    "\n",
    "\n",
    "    # dataset\n",
    "    train_loader, val_loader, test_loader, num_nodes, seq_length, num_classes = get_default_train_val_test_loader(args)\n",
    "    \n",
    "    print('features / nodes', num_nodes,'total time graphs',args['groups'],'time series length',seq_length,'classes', num_classes)\n",
    "    \n",
    "    # training model from net.py\n",
    "    model = GNNStack(gnn_model_type=args['arch'], num_layers=args['num_layers'], \n",
    "                     groups=args['groups'], pool_ratio=args['pool_ratio'], kern_size=args['kern_size'], \n",
    "                     in_dim=args['in_dim'], hidden_dim=args['hidden_dim'], out_dim=args['out_dim'], \n",
    "                     seq_len=seq_length, num_nodes=num_nodes, num_classes=num_classes)\n",
    "\n",
    "    # print & log\n",
    "    log_msg('epochs {}, lr {}, weight_decay {}'.format(args['epochs'], args['lr'], args['weight_decay']), log_file)\n",
    "    \n",
    "    log_msg(str(args), log_file)\n",
    "\n",
    "\n",
    "    # determine whether GPU or not\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"Warning! Using CPU!!!\")\n",
    "    elif args['gpu'] is not None:\n",
    "        torch.cuda.set_device(args['gpu'])\n",
    "\n",
    "        # collect cache\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model = model.cuda(args['gpu'])\n",
    "        if args['use_benchmark']:\n",
    "            cudnn.benchmark = True\n",
    "        print('Using cudnn.benchmark.')\n",
    "    else:\n",
    "        print(\"Error! We only have one gpu!!!\")\n",
    "\n",
    "\n",
    "    # define loss function(criterion) and optimizer\n",
    "    # class_weights = torch.tensor([0.087, 0.913], dtype=torch.float).cuda(args['gpu'])\n",
    "    # class_weights = torch.tensor([0.913, 0.087], dtype=torch.float).cuda(args['gpu'])\n",
    "    # class_weights = torch.tensor([1.0, 22.47], dtype=torch.float).cuda(args['gpu'])\n",
    "    \n",
    "    \n",
    "    # criterion = nn.CrossEntropyLoss(weight=class_weights).cuda(args['gpu'])\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().cuda(args['gpu'])\n",
    "    \n",
    "    # TODO\n",
    "    # criterion = FocalLoss(gamma=0.1)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "    \n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    # validation\n",
    "    if args['evaluate']:\n",
    "        validate(val_loader, model, criterion, args)\n",
    "        return\n",
    "\n",
    "    # train & valid\n",
    "    print('****************************************************')\n",
    "    print('Dataset: ', args['dataset'])\n",
    "\n",
    "    dataset_time = AverageMeter('Time', ':6.3f')\n",
    "\n",
    "    loss_train = []\n",
    "    acc_train = []\n",
    "    loss_val = []\n",
    "    acc_val = []\n",
    "    epoches = []\n",
    "    \n",
    "    ########################\n",
    "    loss_test = []\n",
    "    acc_test  = []\n",
    "    #######################\n",
    "    \n",
    "    ###### more lists to have values\n",
    "    roc_train = []\n",
    "    pr_train  = []\n",
    "    f1_train  = []\n",
    "    mcc_train = []\n",
    "    \n",
    "    roc_val   = []\n",
    "    pr_val    = []\n",
    "    f1_val    = []\n",
    "    mcc_val   = []\n",
    "    ##################################################\n",
    "    roc_test   = []\n",
    "    pr_test    = []\n",
    "    f1_test    = []\n",
    "    mcc_test   = []     \n",
    "    #################################################\n",
    "    end = time.time()\n",
    "    for epoch in tqdm(range(args['epochs'])):\n",
    "    # for epoch in range(args['epochs']):\n",
    "        epoches += [epoch]\n",
    "\n",
    "        # train for one epoch\n",
    "        acc_train_per, loss_train_per, output_train_per, target_train_per = train(train_loader, model, criterion, optimizer, lr_scheduler, args)\n",
    "        \n",
    "        acc_train += [acc_train_per]\n",
    "        loss_train += [loss_train_per]\n",
    "        # calculate metric\n",
    "        # print(len(target_train_per),len(output_train_per))\n",
    "        auc_roc_value_train = roc_auc_score(target_train_per, output_train_per)\n",
    "        auc_pr_value_train = average_precision_score(target_train_per, output_train_per)\n",
    "        p2l_value_train = np.where(np.array(output_train_per) >= 0.5, 1, 0)\n",
    "        f1_value_train = f1_score(target_train_per, p2l_value_train.tolist())\n",
    "        mcc_value_train= matthews_corrcoef(target_train_per,p2l_value_train.tolist())\n",
    "        \n",
    "        #new code\n",
    "        roc_train += [auc_roc_value_train]\n",
    "        pr_train  += [auc_pr_value_train]\n",
    "        f1_train  += [f1_value_train]\n",
    "        mcc_train  += [mcc_value_train]\n",
    "\n",
    "        msg = f'TRAIN, epoch {epoch}, train_loss {loss_train_per}, train_acc {acc_train_per}, train_roc {auc_roc_value_train:.5f}, \\\n",
    "                train_pr {auc_pr_value_train:.5f}, train_f1 {f1_value_train:.5f},train_mcc {mcc_value_train:.5f}'\n",
    "\n",
    "        print(f'TRAIN, epoch {epoch}, train_loss {loss_train_per:.5f}, train_roc {auc_roc_value_train:.5f}, train_pr {auc_pr_value_train:.5f}, train_f1 {f1_value_train:.5f}, train_mcc {mcc_value_train:.5f}')\n",
    "        # tqdm.write(f'TRAIN, epoch {epoch}, train_loss {loss_train_per:.5f}, train_roc {auc_roc_value_train:.5f}, train_pr {auc_pr_value_train:.5f}, train_f1 {f1_value_train:.5f}, train_mcc {mcc_value_train:.5f}')\n",
    "        log_msg(msg, log_file)\n",
    "\n",
    "        \n",
    "        # evaluate on validation set\n",
    "        acc_val_per, loss_val_per, output_val_per, target_val_per = validate(val_loader, model, criterion, args)\n",
    "\n",
    "        acc_val  += [acc_val_per]\n",
    "        loss_val += [loss_val_per]\n",
    "        #calculate metric\n",
    "        # calculate metric\n",
    "        # print(len(target_val_per),len(output_val_per))\n",
    "        auc_roc_value_val = roc_auc_score(target_val_per, output_val_per)\n",
    "        auc_pr_value_val = average_precision_score(target_val_per, output_val_per)\n",
    "        p2l_value_val = np.where(np.array(output_val_per) >= 0.5, 1, 0)\n",
    "        f1_value_val = f1_score(target_val_per, p2l_value_val.tolist())\n",
    "        mcc_value_val= matthews_corrcoef(target_val_per,p2l_value_val.tolist())\n",
    "        #new code\n",
    "\n",
    "        msg = f'VAL, epoch {epoch}, val_loss {loss_val_per}, val_acc {acc_val_per}, val_roc {auc_roc_value_val:.5f}, val_pr {auc_pr_value_val:.5f},val_f1 {f1_value_val:.5f}, val_mcc {mcc_value_val:.5f}'\n",
    "        \n",
    "        print(f'VAL, epoch {epoch}, val_loss {loss_val_per:.5f}, val_roc {auc_roc_value_val:.5f}, val_pr {auc_pr_value_val:.5f},val_f1 {f1_value_val:.5f}, val_mcc {mcc_value_val:.5f}')\n",
    "        # tqdm.write(f'VAL, epoch {epoch}, val_loss {loss_val_per:.5f}, val_roc {auc_roc_value_val:.5f}, val_pr {auc_pr_value_val:.5f},val_f1 {f1_value_val:.5f}, val_mcc {mcc_value_val:.5f}')\n",
    "        log_msg(msg, log_file)\n",
    "        #########################################################################################################################\n",
    "        # evaluate on test set\n",
    "        acc_test_per, loss_test_per, output_test_per, target_test_per = validate(test_loader, model, criterion, args)\n",
    "\n",
    "        acc_test   += [acc_test_per]\n",
    "        loss_test  += [loss_test_per]\n",
    "        #calculate metric\n",
    "        # calculate metric\n",
    "        # print(len(target_val_per),len(output_val_per))\n",
    "        auc_roc_value_test = roc_auc_score(target_test_per, output_test_per)\n",
    "        auc_pr_value_test  = average_precision_score(target_test_per, output_test_per)\n",
    "        p2l_value_test = np.where(np.array(output_test_per) >= 0.5, 1, 0)\n",
    "        f1_value_test = f1_score(target_test_per, p2l_value_test.tolist())\n",
    "        mcc_value_test= matthews_corrcoef(target_test_per,p2l_value_test.tolist())\n",
    "        #new code\n",
    "\n",
    "        msg = f'TEST, epoch {epoch},test_loss {loss_test_per},test_acc {acc_test_per},test_roc {auc_roc_value_test:.5f},test_pr {auc_pr_value_test:.5f},test_f1 {f1_value_test:.5f}, test_mcc {mcc_value_test:.5f}'\n",
    "        print(f'TEST, epoch {epoch}, test_loss {loss_test_per:.5f}, test_roc {auc_roc_value_test:.5f}, test_pr {auc_pr_value_test:.5f}, test_f1 {f1_value_test:.5f}, test_mcc {mcc_value_test:.5f}')\n",
    "        # tqdm.write(f'TEST, epoch {epoch}, test_loss {loss_test_per:.5f}, test_roc {auc_roc_value_test:.5f}, test_pr {auc_pr_value_test:.5f}, test_f1 {f1_value_test:.5f}, test_mcc {mcc_value_test:.5f}')\n",
    "        log_msg(msg, log_file)        \n",
    "        \n",
    "        #########################################################################################################################\n",
    "        # remember best acc\n",
    "        best_acc1 = max(acc_val_per, best_acc1)\n",
    "        best_roc  = max(auc_roc_value_val, best_roc)\n",
    "        best_pr   = max(auc_pr_value_val, best_pr)\n",
    "        best_f1   = max(f1_value_val, best_f1)\n",
    "        best_mcc   = max(mcc_value_val, best_mcc)\n",
    "        \n",
    "        #########################################################################################################################\n",
    "        \n",
    "        best_test_acc1 = max(acc_test_per, best_test_acc1)\n",
    "        best_test_roc  = max(auc_roc_value_test, best_test_roc)\n",
    "        best_test_pr   = max(auc_pr_value_test, best_test_pr)\n",
    "        best_test_f1   = max(f1_value_test, best_test_f1)\n",
    "        best_test_mcc   = max(mcc_value_test, best_test_mcc)\n",
    " \n",
    "\n",
    "    #     wandb.log({\"train_loss\": loss_train_per, \"train_roc\": auc_roc_value_train, \"train_pr\": auc_pr_value_train, \\\n",
    "    #                \"val_loss\": loss_val_per, \"val_roc\": auc_roc_value_val, \"val_pr\": auc_pr_value_val, \"best_val_roc\": best_roc, \"best_val_pr\": best_pr})\n",
    "    # wandb.finish()\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Construct the filename with metrics\n",
    "        auc_roc_value_val_scalar = auc_roc_value_val.item() if isinstance(auc_roc_value_val, torch.Tensor) else auc_roc_value_val\n",
    "        auc_pr_value_val_scalar  = auc_pr_value_val.item() if isinstance(auc_pr_value_val, torch.Tensor) else auc_pr_value_val\n",
    "        f1_value_val_scalar      = f1_value_val.item() if isinstance(f1_value_val, torch.Tensor) else f1_value_val\n",
    "        mcc_value_val_scalar     = mcc_value_val.item() if isinstance(mcc_value_val, torch.Tensor) else mcc_value_val\n",
    "        #########################################################################################################################\n",
    "        auc_roc_value_test_scalar = auc_roc_value_test.item() if isinstance(auc_roc_value_test, torch.Tensor) else auc_roc_value_test\n",
    "        auc_pr_value_test_scalar  = auc_pr_value_test.item() if isinstance(auc_pr_value_test, torch.Tensor) else auc_pr_value_test\n",
    "        f1_value_test_scalar      = f1_value_test.item() if isinstance(f1_value_test, torch.Tensor) else f1_value_test\n",
    "        mcc_value_test_scalar      = mcc_value_test.item() if isinstance(mcc_value_test, torch.Tensor) else mcc_value_test        \n",
    "        #########################################################################################################################\n",
    "        # Now use these scalar values in the filename\n",
    "        filename = f\"model_epoch_{epoch}.pth\"\n",
    "       \n",
    "        # Continue with the existing logic to save the model\n",
    "        model_path = os.path.join(specific_model_save_dir, filename)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # measure elapsed time\n",
    "    dataset_time.update(time.time() - end)\n",
    "\n",
    "    # log & print the best_acc\n",
    "    msg = f'\\n\\n * BEST_ACC: {best_acc1}\\n * TIME: {dataset_time}\\n'\n",
    "    log_msg(msg, log_file)\n",
    "\n",
    "    print(f' * best_acc1: {best_acc1}, best_roc: {best_roc}, best_pr: {best_pr}, best_f1: {best_f1}, best_mcc: {best_mcc}')\n",
    "    print(f' * best_test_acc1: {best_test_acc1}, best_test_roc: {best_test_roc}, best_test_pr: {best_test_pr}, best_test_f1: {best_test_f1}, best_test_mcc: {best_test_mcc}')\n",
    "    print(f' * time: {dataset_time}')\n",
    "    print('****************************************************')\n",
    "\n",
    "\n",
    "    # collect cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, lr_scheduler, args):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc', ':6.2f')\n",
    "    # met_roc = AverageMeter('ROC', ':6.2f')\n",
    "    # met_pr = AverageMeter('PR', ':6.2f')\n",
    "    \n",
    "    output_list = []\n",
    "    target_list = [] \n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for count, (data, label, mask) in enumerate(train_loader):\n",
    "\n",
    "        # data in cuda\n",
    "        data = data.cuda(args['gpu']).type(torch.float)\n",
    "        data = data.view(data.size(0), 1, data.size(2), data.size(1))\n",
    "        mask = mask.cuda(args['gpu']).type(torch.bool)\n",
    "        label = label.cuda(args['gpu']).type(torch.long)\n",
    "\n",
    "        # compute output\n",
    "        output = model(data)\n",
    "        # print(len(output))\n",
    "        # print('output', output.shape, 'mask', mask.shape)\n",
    "        out_flat = torch.masked_select(output, mask.unsqueeze(-1)).reshape(-1, output.shape[-1])\n",
    "        # print(output)\n",
    "        # print(output.shape, mask.shape, out_flat.shape)\n",
    "        # break\n",
    "        # out_flat = torch.masked_select(output[:,:,1], mask)\n",
    "        \n",
    "\n",
    "        label_flat = torch.masked_select(label, mask)\n",
    "        # print('output',output.shape, 'mask', mask.shape,'out_flat', out_flat.shape, 'label', label.shape, 'label_flat', label_flat.shape)\n",
    "        loss = criterion(out_flat, label_flat)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1 = accuracy(out_flat, label_flat, topk=(1, 1))\n",
    "        \n",
    "        output_np = torch.softmax(out_flat, dim=1).detach().cpu().numpy()[:,1].tolist()\n",
    "        \n",
    "        target_np = label_flat.detach().cpu().numpy().tolist()\n",
    "        \n",
    "        # print(output_np, target_np)\n",
    "        \n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        top1.update(acc1[0], data.size(0))\n",
    "        \n",
    "        # met_roc.update(roc, data.size(0))\n",
    "        # met_pr.update(pr, data.size(0))\n",
    "        output_list += output_np\n",
    "        target_list += target_np\n",
    "\n",
    "        # compute gradient and do Adam step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    lr_scheduler.step(top1.avg)\n",
    "\n",
    "    return top1.avg, losses.avg, output_list, target_list\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, args):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # met_roc = AverageMeter('ROC', ':6.2f')\n",
    "    # met_pr = AverageMeter('PR', ':6.2f')\n",
    "    output_list = []\n",
    "    target_list = [] \n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for count, (data, label, mask) in enumerate(val_loader):\n",
    "            if args['gpu'] is not None:\n",
    "                data = data.cuda(args['gpu'], non_blocking=True).type(torch.float)\n",
    "                data = data.view(data.size(0), 1, data.size(2), data.size(1))\n",
    "            if torch.cuda.is_available():\n",
    "                label = label.cuda(args['gpu'], non_blocking=True).type(torch.long)\n",
    "                mask  = mask.cuda(args['gpu'], non_blocking=True).type(torch.bool)\n",
    "\n",
    "            # compute output\n",
    "            output = model(data)\n",
    "            \n",
    "            out_flat = torch.masked_select(output, mask.unsqueeze(-1)).reshape(-1, output.shape[-1])\n",
    "            label_flat = torch.masked_select(label, mask)\n",
    "\n",
    "            loss = criterion(out_flat, label_flat)\n",
    "            \n",
    "            output_np = torch.softmax(out_flat, dim=1).detach().cpu().numpy()[:,1].tolist()\n",
    "            target_np = label_flat.detach().cpu().numpy().tolist()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1 = accuracy(out_flat, label_flat, topk=(1, 1))\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            top1.update(acc1[0], data.size(0))\n",
    "            \n",
    "            output_list += output_np\n",
    "            target_list += target_np\n",
    "            \n",
    "            # met_roc.update(roc, data.size(0))\n",
    "            # met_pr.update(pr, data.size(0))\n",
    "\n",
    "    return top1.avg, losses.avg, output_list, target_list\n",
    "\n",
    "def load_model(model_path, model_class, *model_args, **model_kwargs):\n",
    "    \"\"\"\n",
    "    Load the model from a saved state dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path: Path to the saved model state dictionary.\n",
    "    - model_class: The class of the model to instantiate.\n",
    "    - model_args: Positional arguments for the model class instantiation.\n",
    "    - model_kwargs: Keyword arguments for the model class instantiation.\n",
    "\n",
    "    Returns:\n",
    "    - model: The loaded model ready for prediction.\n",
    "    \"\"\"\n",
    "    # Instantiate the model\n",
    "    model = model_class(*model_args, **model_kwargs)\n",
    "    # Load the saved state dictionary\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "# def predict(test_loader, model, criterion, args):\n",
    "#     \"\"\"\n",
    "#     Predict the labels for the given data using the loaded model.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model: The loaded model ready for prediction.\n",
    "#     - data_loader: DataLoader for the dataset to predict on.\n",
    "\n",
    "#     Returns:\n",
    "#     - predictions: Predictions for the input data.\n",
    "#     \"\"\"\n",
    "#     predictions = []\n",
    "#     with torch.no_grad():  # No need to track gradients\n",
    "#         for data in test_loader:\n",
    "#             # Assuming your model expects data in a specific format, adjust accordingly\n",
    "#             if torch.cuda.is_available():\n",
    "#                 data = data.to('cuda')\n",
    "#             output = model(data)\n",
    "#             # Convert output to probabilities and then to the desired format\n",
    "#             # For example, using softmax for classification\n",
    "#             prob = torch.softmax(output, dim=1)\n",
    "#             predicted_classes = prob.argmax(dim=1)\n",
    "#             predictions.append(predicted_classes.cpu().numpy())  # Move to CPU and convert to numpy if needed\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adbbabaa-9dd4-49ae-be54-909c542b649e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be saved in: saved_models/Resp_failure_development_attentionMSE_03.03 19:33\n",
      "Use GPU: 0 for training\n",
      "features / nodes 231 total time graphs 32 time series length 864 classes 2\n",
      "Using cudnn.benchmark.\n",
      "****************************************************\n",
      "Dataset:  Resp_failure_development_attentionMSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN, epoch 0, train_loss 0.67533, train_roc 0.58273, train_pr 0.47674, train_f1 0.43833, train_mcc 0.11019\n",
      "VAL, epoch 0, val_loss 0.63599, val_roc 0.67714, val_pr 0.56967,val_f1 0.52421, val_mcc 0.25493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                      | 1/20 [29:40<9:23:49, 1780.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 0, test_loss 0.63486, test_roc 0.67450, test_pr 0.56987, test_f1 0.51791, test_mcc 0.25297\n",
      "TRAIN, epoch 1, train_loss 0.60119, train_roc 0.72098, train_pr 0.63292, train_f1 0.56573, train_mcc 0.31476\n",
      "VAL, epoch 1, val_loss 0.58900, val_roc 0.73509, val_pr 0.65450,val_f1 0.58592, val_mcc 0.33404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                    | 2/20 [59:05<8:51:20, 1771.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 1, test_loss 0.58678, test_roc 0.73542, test_pr 0.65677, test_f1 0.58199, test_mcc 0.33631\n",
      "TRAIN, epoch 2, train_loss 0.56881, train_roc 0.75773, train_pr 0.68317, train_f1 0.60445, train_mcc 0.37301\n",
      "VAL, epoch 2, val_loss 0.57911, val_roc 0.76209, val_pr 0.68428,val_f1 0.52884, val_mcc 0.36406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▋                                | 3/20 [1:28:03<8:17:35, 1756.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 2, test_loss 0.57613, test_roc 0.76189, test_pr 0.68648, test_f1 0.52786, test_mcc 0.37090\n",
      "TRAIN, epoch 3, train_loss 0.54902, train_roc 0.77754, train_pr 0.70961, train_f1 0.62481, train_mcc 0.40304\n",
      "VAL, epoch 3, val_loss 0.55265, val_roc 0.77499, val_pr 0.69986,val_f1 0.62151, val_mcc 0.39473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▌                              | 4/20 [1:57:14<7:47:44, 1754.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 3, test_loss 0.54905, test_roc 0.77539, test_pr 0.70446, test_f1 0.62161, test_mcc 0.40254\n",
      "TRAIN, epoch 4, train_loss 0.53777, train_roc 0.78859, train_pr 0.72428, train_f1 0.63656, train_mcc 0.42000\n",
      "VAL, epoch 4, val_loss 0.55116, val_roc 0.77621, val_pr 0.70545,val_f1 0.62136, val_mcc 0.40349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████▌                            | 5/20 [2:26:06<7:16:34, 1746.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 4, test_loss 0.54474, test_roc 0.78012, test_pr 0.71337, test_f1 0.62375, test_mcc 0.41460\n",
      "TRAIN, epoch 5, train_loss 0.52776, train_roc 0.79726, train_pr 0.73477, train_f1 0.64684, train_mcc 0.43491\n",
      "VAL, epoch 5, val_loss 0.54476, val_roc 0.78204, val_pr 0.70808,val_f1 0.61973, val_mcc 0.40715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▍                          | 6/20 [2:55:47<6:50:11, 1757.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 5, test_loss 0.53629, test_roc 0.78757, test_pr 0.71693, test_f1 0.62168, test_mcc 0.41973\n",
      "TRAIN, epoch 6, train_loss 0.51861, train_roc 0.80426, train_pr 0.74333, train_f1 0.65460, train_mcc 0.44657\n",
      "VAL, epoch 6, val_loss 0.53850, val_roc 0.78741, val_pr 0.71612,val_f1 0.62857, val_mcc 0.41530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████▎                        | 7/20 [3:24:44<6:19:24, 1751.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 6, test_loss 0.52870, test_roc 0.79247, test_pr 0.72734, test_f1 0.63258, test_mcc 0.42993\n",
      "TRAIN, epoch 7, train_loss 0.51447, train_roc 0.80926, train_pr 0.74952, train_f1 0.65982, train_mcc 0.45546\n",
      "VAL, epoch 7, val_loss 0.53397, val_roc 0.79354, val_pr 0.72079,val_f1 0.65230, val_mcc 0.42460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▏                      | 8/20 [3:54:28<5:52:18, 1761.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 7, test_loss 0.52410, test_roc 0.79938, test_pr 0.73203, test_f1 0.65754, test_mcc 0.43820\n",
      "TRAIN, epoch 8, train_loss 0.50791, train_roc 0.81432, train_pr 0.75501, train_f1 0.66517, train_mcc 0.46366\n",
      "VAL, epoch 8, val_loss 0.53365, val_roc 0.79351, val_pr 0.72103,val_f1 0.64016, val_mcc 0.42568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████                     | 9/20 [4:24:00<5:23:33, 1764.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 8, test_loss 0.52265, test_roc 0.79998, test_pr 0.73179, test_f1 0.64562, test_mcc 0.44160\n",
      "TRAIN, epoch 9, train_loss 0.50326, train_roc 0.81887, train_pr 0.76113, train_f1 0.67101, train_mcc 0.47119\n",
      "VAL, epoch 9, val_loss 0.53185, val_roc 0.79362, val_pr 0.72326,val_f1 0.63963, val_mcc 0.42957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████▌                  | 10/20 [4:52:57<4:52:42, 1756.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 9, test_loss 0.52405, test_roc 0.79692, test_pr 0.73149, test_f1 0.64095, test_mcc 0.43844\n",
      "TRAIN, epoch 10, train_loss 0.49800, train_roc 0.82262, train_pr 0.76611, train_f1 0.67539, train_mcc 0.47958\n",
      "VAL, epoch 10, val_loss 0.53000, val_roc 0.79629, val_pr 0.72626,val_f1 0.65060, val_mcc 0.43397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████▎                | 11/20 [5:22:00<4:22:49, 1752.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 10, test_loss 0.52231, test_roc 0.79968, test_pr 0.73464, test_f1 0.65168, test_mcc 0.44160\n",
      "TRAIN, epoch 11, train_loss 0.49721, train_roc 0.82475, train_pr 0.76952, train_f1 0.67766, train_mcc 0.48239\n",
      "VAL, epoch 11, val_loss 0.53357, val_roc 0.79988, val_pr 0.72631,val_f1 0.63341, val_mcc 0.43348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████▏              | 12/20 [5:51:21<3:53:58, 1754.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 11, test_loss 0.52359, test_roc 0.80239, test_pr 0.73583, test_f1 0.63488, test_mcc 0.44282\n",
      "TRAIN, epoch 12, train_loss 0.49150, train_roc 0.82915, train_pr 0.77459, train_f1 0.68404, train_mcc 0.49113\n",
      "VAL, epoch 12, val_loss 0.53142, val_roc 0.79680, val_pr 0.72635,val_f1 0.65043, val_mcc 0.43321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████             | 13/20 [6:21:39<3:26:58, 1774.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 12, test_loss 0.51793, test_roc 0.80450, test_pr 0.73869, test_f1 0.65710, test_mcc 0.45118\n",
      "TRAIN, epoch 13, train_loss 0.48864, train_roc 0.83224, train_pr 0.77809, train_f1 0.68542, train_mcc 0.49465\n",
      "VAL, epoch 13, val_loss 0.52718, val_roc 0.79927, val_pr 0.72864,val_f1 0.65866, val_mcc 0.43686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████▉           | 14/20 [6:50:54<2:56:49, 1768.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 13, test_loss 0.51822, test_roc 0.80407, test_pr 0.73828, test_f1 0.66419, test_mcc 0.45021\n",
      "TRAIN, epoch 14, train_loss 0.48192, train_roc 0.83556, train_pr 0.78248, train_f1 0.69248, train_mcc 0.50250\n",
      "VAL, epoch 14, val_loss 0.52771, val_roc 0.80132, val_pr 0.73142,val_f1 0.64270, val_mcc 0.43963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████▊         | 15/20 [7:19:05<2:25:24, 1744.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 14, test_loss 0.51496, test_roc 0.80753, test_pr 0.74367, test_f1 0.64920, test_mcc 0.45716\n",
      "TRAIN, epoch 15, train_loss 0.47900, train_roc 0.83948, train_pr 0.78722, train_f1 0.69611, train_mcc 0.50858\n",
      "VAL, epoch 15, val_loss 0.53381, val_roc 0.79900, val_pr 0.72431,val_f1 0.64790, val_mcc 0.43740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████▌       | 16/20 [7:47:16<1:55:14, 1728.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 15, test_loss 0.51777, test_roc 0.80660, test_pr 0.73910, test_f1 0.65540, test_mcc 0.45509\n",
      "TRAIN, epoch 16, train_loss 0.47412, train_roc 0.84268, train_pr 0.79103, train_f1 0.69942, train_mcc 0.51438\n",
      "VAL, epoch 16, val_loss 0.53014, val_roc 0.79745, val_pr 0.72405,val_f1 0.65215, val_mcc 0.43388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████▍     | 17/20 [8:15:26<1:25:51, 1717.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 16, test_loss 0.51597, test_roc 0.80610, test_pr 0.73963, test_f1 0.66113, test_mcc 0.45310\n",
      "TRAIN, epoch 17, train_loss 0.46922, train_roc 0.84652, train_pr 0.79564, train_f1 0.70480, train_mcc 0.52210\n",
      "VAL, epoch 17, val_loss 0.52911, val_roc 0.80067, val_pr 0.72553,val_f1 0.64825, val_mcc 0.44019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████    | 18/20 [8:43:37<56:58, 1709.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 17, test_loss 0.51239, test_roc 0.80944, test_pr 0.74147, test_f1 0.65816, test_mcc 0.46006\n",
      "TRAIN, epoch 18, train_loss 0.46572, train_roc 0.84917, train_pr 0.79931, train_f1 0.70797, train_mcc 0.52660\n",
      "VAL, epoch 18, val_loss 0.53493, val_roc 0.80100, val_pr 0.72643,val_f1 0.64473, val_mcc 0.43937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████  | 19/20 [9:11:48<28:23, 1703.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 18, test_loss 0.51895, test_roc 0.80865, test_pr 0.74184, test_f1 0.65279, test_mcc 0.45606\n",
      "TRAIN, epoch 19, train_loss 0.46068, train_roc 0.85210, train_pr 0.80326, train_f1 0.71073, train_mcc 0.53229\n",
      "VAL, epoch 19, val_loss 0.52872, val_roc 0.80334, val_pr 0.72993,val_f1 0.65954, val_mcc 0.44444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 20/20 [9:39:59<00:00, 1739.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 19, test_loss 0.51374, test_roc 0.81117, test_pr 0.74603, test_f1 0.66922, test_mcc 0.46581\n",
      " * best_acc1: tensor([74.0154], device='cuda:0'), best_roc: 0.8033370457495794, best_pr: 0.7314193522293397, best_f1: 0.6595373010876141, best_mcc: 0.4444436657029826\n",
      " * best_test_acc1: tensor([75.0710], device='cuda:0'), best_test_roc: 0.8111713437523786, best_test_pr: 0.746031695483067, best_test_f1: 0.6692231407014086, best_test_mcc: 0.4658092798187367\n",
      " * time: Time 34799.484 (34799.484)\n",
      "****************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_work(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b51cb77-ecaa-48d1-8625-d397425b17f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58cefe-c901-4fbb-8fa2-e0a36b90e146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
