{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9fc933-5024-468d-91bd-6408aa8297b9",
   "metadata": {},
   "source": [
    "![alt text](05_kidney_metrics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a02078-96b3-4f14-9669-fb49f4edb4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be49837-23e5-418a-a1f6-aa834f8bb18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from loader import ICUVariableLengthLoaderTables, ICUVariableLengthDataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289ba758-e261-48fa-ac80-f8d81e62fce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'NVIDIA GeForce RTX 4060 Ti')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.is_available(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e40d61-adfc-430c-96e2-0a205a366cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c014230b-cda3-4cbc-920a-2d5b16570858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from net_dev import GNNStack\n",
    "# from utils_todynet_binary import AverageMeter, accuracy, log_msg, get_default_train_val_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5d7406-8f67-45bd-add7-cb4a8fe7a97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a458334-b4e5-4c9b-bacb-976cb10ec9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=None, gamma=2):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         loss = (self.alpha[targets] * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "#         return loss\n",
    "\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=None, gamma=2, num_classes=None):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.gamma = gamma\n",
    "#         if alpha is None:\n",
    "#             self.alpha = None\n",
    "#         else:\n",
    "#             # If alpha is a single float number, expand it to a tensor\n",
    "#             if isinstance(alpha, float):\n",
    "#                 assert num_classes is not None, \"num_classes must be specified when alpha is a single float\"\n",
    "#                 self.alpha = torch.full((num_classes,), alpha)\n",
    "#             else:\n",
    "#                 self.alpha = alpha\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         if self.alpha is not None:\n",
    "#             if self.alpha.type() != inputs.data.type():\n",
    "#                 self.alpha = self.alpha.type_as(inputs.data)\n",
    "#             at = self.alpha[targets]\n",
    "#         else:\n",
    "#             at = 1.0\n",
    "#         loss = (at * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b608f5b7-259a-4fea-be59-b90be979c3b9",
   "metadata": {},
   "source": [
    "## aruguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e2de2d-8c0d-4ab8-8090-5e5621f13034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'arch': 'dyGIN2d', #what other models I can put here?? dyGCN2d, dyGIN2d\n",
    "    'dataset': 'Kidney_Reg_attentionMSE', # \"AtrialFibrillation\" # 'Mortality', # 'MIMIC3' Resp_failure\n",
    "    'num_layers': 2,  # the number of GNN layers  3\n",
    "    'groups': 32,  # the number of time series groups (num_graphs)\n",
    "    'pool_ratio': 0.0,  # the ratio of pooling for nodes # initially 0.1 but changed to 0 because the node number was decreasing\n",
    "    'kern_size': [3,3],  # list of time conv kernel size for each layer [9,5,3]\n",
    "    'in_dim': 64,  # input dimensions of GNN stacks\n",
    "    'hidden_dim': 64,  # hidden dimensions of GNN stacks\n",
    "    'out_dim': 64,  # output dimensions of GNN stacks\n",
    "    'workers': 0,  # number of data loading workers\n",
    "    'epochs': 20,  # number of total epochs to run\n",
    "    'batch_size': 8,  # mini-batch size, this is the total batch size of all GPUs\n",
    "    'val_batch_size': 8,  # validation batch size\n",
    "    'lr': 0.0002,  # initial learning rate\n",
    "    'weight_decay': 1e-4,  # weight decay\n",
    "    'evaluate': False,  # evaluate model on validation set\n",
    "    'seed': 3,  # seed for initializing training\n",
    "    'gpu': 0,  # GPU id to use\n",
    "    'use_benchmark': True,  # use benchmark\n",
    "    'tag': 'date',  # the tag for identifying the log and model files\n",
    "    'loss':'bce',\n",
    "    'resample':'5min',\n",
    "    'series_length':2016,\n",
    "}\n",
    "\n",
    "# resample works: 5min, 15 min, 35 min, 45min. analysis will have 5,15,45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8334a7f-fd2c-4bbf-ab0e-826642283b1e",
   "metadata": {},
   "source": [
    "### GPU 2 is used to training in sheet 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584106be-b4fa-4cad-80b0-8f66ad715837",
   "metadata": {},
   "source": [
    "### TODO\n",
    "## Molly douglas has filtered 116 features from 231, ~50% reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "982150c8-5c87-471b-b810-75f52df10c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"mortality\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config=args\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c31c8a0-dcb1-4e0c-b44e-36bb9bd8f4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = TensorDataset(data_train, label_train)\n",
    "# val_dataset   = TensorDataset(data_val, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f6c801-7a9f-4f8a-9cbf-362febcf0683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=args['batch_size'],shuffle=True, num_workers=args['workers'], pin_memory=True)\n",
    "# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args['val_batch_size'], shuffle=False,num_workers=args['workers'],pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a648e31-70d5-4f32-b03a-6fd95b5211e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     # args = parser.parse_args()\n",
    "    \n",
    "#     # args.kern_size = [ int(l) for l in args.kern_size.split(\",\") ]\n",
    "\n",
    "#     # if args.seed is not None:\n",
    "#     random.seed(args['seed'])\n",
    "#     torch.manual_seed(args['seed'])\n",
    "\n",
    "#     main_work(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4c9a44f-2214-47c8-8de8-d47d7ba5202d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "# def accuracy(output, target, topk=(1,)):\n",
    "#     \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    \n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         maxk = max(topk)\n",
    "#         batch_size = target.size(0)\n",
    "\n",
    "#         _, pred = output.topk(maxk, 1, True, True)\n",
    "#         pred = pred.t()\n",
    "              \n",
    "#         correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        \n",
    "#         # print(output, target)\n",
    "\n",
    "#         res = []\n",
    "#         for k in topk:\n",
    "#             correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "#             try:\n",
    "#                 res.append(correct_k.mul_(100.0 / batch_size))\n",
    "#             except:\n",
    "#                 res.append(0)\n",
    "\n",
    "#         return res\n",
    "\n",
    "def log_msg(message, log_file):\n",
    "    with open(log_file, 'a') as f:\n",
    "        print(message, file=f)\n",
    "\n",
    "\n",
    "def get_default_train_val_test_loader(args):\n",
    "\n",
    "    # get dataset-id\n",
    "    dsid = args['dataset']\n",
    "    h5_path= 'h5_folder/ml_stage_12h.h5'\n",
    "    # get dataset from .pt\n",
    "    # data_train  = torch.load(f'data/UCR/{dsid}/X_train.pt')\n",
    "    # data_val    = torch.load(f'data/UCR/{dsid}/X_valid.pt')\n",
    "    # data_val    = torch.load(f'data/UCR/{dsid}/X_test.pt')\n",
    "    \n",
    "    # label_train = torch.load(f'data/UCR/{dsid}/y_train.pt')\n",
    "    # label_val   = torch.load(f'data/UCR/{dsid}/y_valid.pt')\n",
    "    # label_val   = torch.load(f'data/UCR/{dsid}/y_test.pt')\n",
    "\n",
    "    # label_train = label_train.flatten().to(dtype=torch.int64)\n",
    "    # label_val   = label_val.flatten().to(dtype=torch.int64)\n",
    "    # init [num_variables, seq_length, num_classes]\n",
    "    \n",
    "    num_nodes = 231\n",
    "    seq_length = 2016 #288 #2016 ### now we will reduce the sequence length to see the performance in short-range\n",
    "    num_classes = 1\n",
    "\n",
    "\n",
    "    # convert data & labels to TensorDataset\n",
    "    # train_dataset = TensorDataset(data_train, label_train)\n",
    "    # val_dataset = TensorDataset(data_val, label_val)\n",
    "  \n",
    "    task   = 'Dynamic_UrineOutput_2Hours_Reg' #\n",
    "    maxlen            = 2016                                                                                   #|patients|  #-1 =8065  #2016     #difference | mean -1   | median -1  | mean 2016   | median 2016|\n",
    "    data_loader_train = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='train') #|  1364  |  (+)25665  (+)18082  (+)7583      | 1.8155506 | 1.3075098  | 1.7475992   | 1.1815174  |\n",
    "    data_loader_val   = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='val')   #|  295   |  (+)5652   (+)3967   (+)1685      | 1.7644166 | 1.2061048  | 1.8004797   | 1.2085757  |\n",
    "    data_loader_test  = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='test')  #|  311   |  (+)4563   (+)3593   (+)970       | 1.7855672 | 1.2110261  | 1.7289896   | 1.1704105  |\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(data_loader_train, batch_size=4, shuffle=True, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "    val_loader   = DataLoader(data_loader_val,   batch_size=4, shuffle=False, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "    # val_loader  = DataLoader(data_loader_test,  batch_size=4, shuffle=False, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "    test_loader  = DataLoader(data_loader_test,  batch_size=4, shuffle=False, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "\n",
    "\n",
    "    # data_loader\n",
    "    # train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=args['batch_size'],shuffle=True,num_workers=args['workers'], pin_memory=True)\n",
    "    # val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=args['val_batch_size'],shuffle=False,num_workers=args['workers'],pin_memory=True)\n",
    "\n",
    "\n",
    "    return train_loader, val_loader, test_loader, num_nodes, seq_length, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4158b59c-39b7-4ed1-9089-1742241d9e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main_work(args):\n",
    "    \n",
    "    random.seed(args['seed'])\n",
    "    torch.manual_seed(args['seed'])\n",
    "    \n",
    "    \n",
    "    # init metrics\n",
    "    best_mae = 0\n",
    "    best_mse  = 0\n",
    "    best_r2s  = 0\n",
    "    \n",
    "    best_test_mae = 0\n",
    "    best_test_mse  = 0\n",
    "    best_test_r2s   = 0\n",
    "    \n",
    "    if args['tag'] == 'date':\n",
    "        local_date = time.strftime('%m.%d %H:%M', time.localtime(time.time()))\n",
    "        args['tag'] = local_date\n",
    "        \n",
    "    # Use the 'tag' which now contains either the date or a custom tag along with the dataset name for the directory\n",
    "    run_dir_name = f\"{args['dataset']}_{args['tag']}\"\n",
    "   \n",
    "    # Base directory for saving models\n",
    "    base_model_save_dir = \"saved_models\"\n",
    "   \n",
    "    # Specific directory for this run\n",
    "    specific_model_save_dir = os.path.join(base_model_save_dir, run_dir_name)\n",
    "    os.makedirs(specific_model_save_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Models will be saved in: {specific_model_save_dir}\")        \n",
    "\n",
    "\n",
    "    log_file = 'log/{}_gpu{}_{}_{}_exp.txt'.format(args['tag'], args['gpu'], args['arch'], args['dataset'])\n",
    "    \n",
    "    \n",
    "    if args['gpu'] is not None:\n",
    "        print(\"Use GPU: {} for training\".format(args['gpu']))\n",
    "\n",
    "\n",
    "    # dataset\n",
    "    train_loader, val_loader, test_loader, num_nodes, seq_length, num_classes = get_default_train_val_test_loader(args)\n",
    "    \n",
    "    print('features / nodes', num_nodes,'total time graphs',args['groups'],'time series length',seq_length,'classes', num_classes)\n",
    "    \n",
    "    # training model from net.py\n",
    "    model = GNNStack(gnn_model_type=args['arch'], num_layers=args['num_layers'], \n",
    "                     groups=args['groups'], pool_ratio=args['pool_ratio'], kern_size=args['kern_size'], \n",
    "                     in_dim=args['in_dim'], hidden_dim=args['hidden_dim'], out_dim=args['out_dim'], \n",
    "                     seq_len=seq_length, num_nodes=num_nodes, num_classes=num_classes)\n",
    "\n",
    "    # print & log\n",
    "    log_msg('epochs {}, lr {}, weight_decay {}'.format(args['epochs'], args['lr'], args['weight_decay']), log_file)\n",
    "    \n",
    "    log_msg(str(args), log_file)\n",
    "\n",
    "\n",
    "    # determine whether GPU or not\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"Warning! Using CPU!!!\")\n",
    "    elif args['gpu'] is not None:\n",
    "        torch.cuda.set_device(args['gpu'])\n",
    "\n",
    "        # collect cache\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model = model.cuda(args['gpu'])\n",
    "        if args['use_benchmark']:\n",
    "            cudnn.benchmark = True\n",
    "        print('Using cudnn.benchmark.')\n",
    "    else:\n",
    "        print(\"Error! We only have one gpu!!!\")\n",
    "\n",
    "        \n",
    "    criterion = nn.MSELoss().cuda(args['gpu'])\n",
    "       \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "    \n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    # validation\n",
    "    if args['evaluate']:\n",
    "        validate(val_loader, model, criterion, args)\n",
    "        return\n",
    "\n",
    "    # train & valid\n",
    "    print('****************************************************')\n",
    "    print('Dataset: ', args['dataset'])\n",
    "\n",
    "    # dataset_time = AverageMeter('Time', ':6.3f')\n",
    "\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    epoches = []\n",
    "    \n",
    "    ########################\n",
    "    loss_test = []\n",
    "    #######################\n",
    "    \n",
    "    ###### more lists to have values\n",
    "    mae_train = []\n",
    "    mse_train  = []\n",
    "    r2s_train  = []\n",
    "    \n",
    "    mae_val   = []\n",
    "    mse_val    = []\n",
    "    r2s_val    = []\n",
    "    ##################################################\n",
    "    mae_test   = []\n",
    "    mse_test    = []\n",
    "    r2s_test    = []  \n",
    "    #################################################\n",
    "    end = time.time()\n",
    "    for epoch in tqdm(range(args['epochs'])):\n",
    "    # for epoch in range(args['epochs']):\n",
    "        epoches += [epoch]\n",
    "\n",
    "        # train for one epoch\n",
    "        loss_train_per, output_train_per, target_train_per = train(train_loader, model, criterion, optimizer, lr_scheduler, args)\n",
    "        \n",
    "        loss_train += [loss_train_per]\n",
    "        # calculate metric\n",
    "        mae_value_train = mean_absolute_error(target_train_per, output_train_per)\n",
    "        mse_value_train = mean_squared_error(target_train_per, output_train_per)\n",
    "        r2s_value_train = r2_score(target_train_per, output_train_per)\n",
    "        \n",
    "        #new code\n",
    "        mae_train  += [mae_value_train]\n",
    "        mse_train  += [mse_value_train]\n",
    "        r2s_train  += [r2s_value_train]\n",
    "\n",
    "        \n",
    "        msg = f'TRAIN, epoch {epoch}, train_loss {loss_train_per}, train_MAE {mae_value_train:.5f}, train_MSE {mse_value_train:.5f}, train_R2S {r2s_value_train:.5f}'\n",
    "\n",
    "        print(f'TRAIN, epoch {epoch}, train_loss {loss_train_per:.5f}, train_MAE {mae_value_train:.5f}, train_MSE {mse_value_train:.5f}, train_R2S {r2s_value_train:.5f}')\n",
    "        # tqdm.write(f'TRAIN, epoch {epoch}, train_loss {loss_train_per:.5f}, train_roc {auc_roc_value_train:.5f}, train_pr {auc_pr_value_train:.5f}, train_f1 {f1_value_train:.5f}, train_mcc {mcc_value_train:.5f}')\n",
    "        log_msg(msg, log_file)\n",
    "\n",
    "        \n",
    "        # evaluate on validation set -- ####################################################################################\n",
    "        loss_val_per, output_val_per, target_val_per = validate(val_loader, model, criterion, args)\n",
    "\n",
    "        loss_val += [loss_val_per]\n",
    "        #calculate metric\n",
    "        # calculate metric\n",
    "        # print(len(target_val_per),len(output_val_per))\n",
    "        mae_value_val = mean_absolute_error(target_val_per, output_val_per)\n",
    "        mse_value_val = mean_squared_error(target_val_per, output_val_per)\n",
    "        r2s_value_val = r2_score(target_val_per, output_val_per)\n",
    "\n",
    "        \n",
    "        #new code\n",
    "\n",
    "        msg = f'VAL, epoch {epoch}, val_loss {loss_val_per}, val_MAE {mae_value_val:.5f}, val_MSE {mse_value_val:.5f}, val_R2S {r2s_value_val:.5f}'\n",
    "        \n",
    "        print(f'VAL, epoch {epoch}, val_loss {loss_val_per:.5f}, val_MAE {mae_value_val:.5f}, val_MSE {mse_value_val:.5f}, val_R2S {r2s_value_val:.5f}')\n",
    "        # tqdm.write(f'VAL, epoch {epoch}, val_loss {loss_val_per:.5f}, val_roc {auc_roc_value_val:.5f}, val_pr {auc_pr_value_val:.5f},val_f1 {f1_value_val:.5f}, val_mcc {mcc_value_val:.5f}')\n",
    "        log_msg(msg, log_file)\n",
    "        #########################################################################################################################\n",
    "        \n",
    "        # evaluate on test set\n",
    "        loss_test_per, output_test_per, target_test_per = validate(test_loader, model, criterion, args)\n",
    "\n",
    "        loss_test  += [loss_test_per]\n",
    "        #calculate metric\n",
    "        # calculate metric\n",
    "        # print(len(target_val_per),len(output_val_per))\n",
    "        mae_value_test  = mean_absolute_error(target_test_per, output_test_per)\n",
    "        mse_value_test  = mean_squared_error(target_test_per, output_test_per)\n",
    "        r2s_value_test  = r2_score(target_test_per, output_test_per)\n",
    "        #new code\n",
    "\n",
    "        msg = f'TEST, epoch {epoch},test_loss {loss_test_per}, test_MAE {mae_value_test:.5f},test_MSE {mse_value_test:.5f},test_R2S {r2s_value_test:.5f}'\n",
    "        print(f'TEST, epoch {epoch}, test_loss {loss_test_per:.5f}, test_MAE {mae_value_test:.5f}, test_MSE {mse_value_test:.5f}, test_R2S {r2s_value_test:.5f}')\n",
    "        # tqdm.write(f'TEST, epoch {epoch}, test_loss {loss_test_per:.5f}, test_roc {auc_roc_value_test:.5f}, test_pr {auc_pr_value_test:.5f}, test_f1 {f1_value_test:.5f}, test_mcc {mcc_value_test:.5f}')\n",
    "        log_msg(msg, log_file)        \n",
    "        \n",
    "        #########################################################################################################################\n",
    "        # remember best reg metrics\n",
    "        best_mae  = max(mae_value_val, best_mae)\n",
    "        best_mse  = max(mse_value_val, best_mse)\n",
    "        best_r2s  = max(r2s_value_val, best_r2s)\n",
    "        \n",
    "        #########################################################################################################################\n",
    "        \n",
    "        best_test_mae  = max(mae_value_test, best_test_mae)\n",
    "        best_test_mse  = max(mse_value_test, best_test_mse)\n",
    "        best_test_r2s  = max(r2s_value_test, best_test_r2s)\n",
    " \n",
    "\n",
    "    #     wandb.log({\"train_loss\": loss_train_per, \"train_roc\": auc_roc_value_train, \"train_pr\": auc_pr_value_train, \\\n",
    "    #                \"val_loss\": loss_val_per, \"val_roc\": auc_roc_value_val, \"val_pr\": auc_pr_value_val, \"best_val_roc\": best_roc, \"best_val_pr\": best_pr})\n",
    "    # wandb.finish()\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Construct the filename with metrics\n",
    "        mae_value_val_scalar      = mae_value_val.item() if isinstance(mae_value_val, torch.Tensor) else mae_value_val\n",
    "        mse_value_val_scalar      = mse_value_val.item() if isinstance(mse_value_val, torch.Tensor) else mse_value_val\n",
    "        r2s_value_val_scalar      = r2s_value_val.item() if isinstance(r2s_value_val, torch.Tensor) else r2s_value_val\n",
    "        #########################################################################################################################\n",
    "        mae_value_test_scalar     = mae_value_test.item() if isinstance(mae_value_test, torch.Tensor) else mae_value_test\n",
    "        mse_value_test_scalar     = mse_value_test.item() if isinstance(mse_value_test, torch.Tensor) else mse_value_test\n",
    "        r2s_value_test_scalar     = r2s_value_test.item() if isinstance(r2s_value_test, torch.Tensor) else r2s_value_test\n",
    "        #########################################################################################################################\n",
    "        # Now use these scalar values in the filename\n",
    "        filename = f\"model_epoch_{epoch}.pth\"\n",
    "       \n",
    "        # Continue with the existing logic to save the model\n",
    "        model_path = os.path.join(specific_model_save_dir, filename)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # measure elapsed time\n",
    "    dataset_time.update(time.time() - end)\n",
    "\n",
    "    # log & print the best_acc\n",
    "    msg = f'\\n\\n * BEST_MAE: {best_mae}\\n * TIME: {dataset_time}\\n'\n",
    "    log_msg(msg, log_file)\n",
    "\n",
    "    print(f' * best_MAE: {best_mae}, best_MSE: {best_mse}, best_R2S: {best_r2s}')\n",
    "    print(f' * best_test_MAE: {best_test_mae}, best_test_MSE: {best_test_mse}, best_test_R2S: {best_test_r2s}')\n",
    "    print(f' * time: {dataset_time}')\n",
    "    print('****************************************************')\n",
    "\n",
    "\n",
    "    # collect cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fdb619d-50f8-4ae5-b0bb-3f4dff0126b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, lr_scheduler, args):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    # top1 = AverageMeter('Acc', ':6.2f')\n",
    "    # met_roc = AverageMeter('ROC', ':6.2f')\n",
    "    # met_pr = AverageMeter('PR', ':6.2f')\n",
    "    \n",
    "    output_list = []\n",
    "    target_list = [] \n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for count, (data, label, mask) in enumerate(train_loader):\n",
    "\n",
    "        # data in cuda\n",
    "        data = data.cuda(args['gpu']).type(torch.float)\n",
    "        data = data.view(data.size(0), 1, data.size(2), data.size(1))\n",
    "        mask = mask.cuda(args['gpu']).type(torch.bool)\n",
    "        label = label.cuda(args['gpu']).type(torch.float) ### although its a regression value but its called label following the source code from classification\n",
    "\n",
    "        # compute output\n",
    "        output = model(data)\n",
    "        # print(len(output))\n",
    "        # print('output', output.shape, 'mask', mask.shape)\n",
    "        out_flat = torch.masked_select(output.squeeze(), mask)\n",
    "        # print(output)\n",
    "        # print(output.shape, mask.shape, out_flat.shape)\n",
    "        # break\n",
    "        # out_flat = torch.masked_select(output[:,:,1], mask)\n",
    "        \n",
    "\n",
    "        label_flat = torch.masked_select(label, mask)\n",
    "        # print('output',output.shape, 'mask', mask.shape,'out_flat', out_flat.shape, 'label', label.shape, 'label_flat', label_flat.shape)\n",
    "        loss = criterion(out_flat, label_flat)\n",
    "        \n",
    "        # print(out_flat, label_flat)\n",
    "        \n",
    "        # record loss\n",
    "        \n",
    "        output_np = out_flat.detach().cpu().numpy().tolist()\n",
    "        \n",
    "        target_np = label_flat.detach().cpu().numpy().tolist()\n",
    "        \n",
    "        # print(output_np, target_np)\n",
    "        \n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        \n",
    "        output_list += output_np\n",
    "        target_list += target_np\n",
    "\n",
    "        # compute gradient and do Adam step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    step_mae = mean_absolute_error(target_list, output_list)\n",
    "\n",
    "    lr_scheduler.step(step_mae)\n",
    "\n",
    "    return losses.avg, output_list, target_list\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, args):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    # top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # met_roc = AverageMeter('ROC', ':6.2f')\n",
    "    # met_pr = AverageMeter('PR', ':6.2f')\n",
    "    \n",
    "    output_list = []\n",
    "    target_list = [] \n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for count, (data, label, mask) in enumerate(val_loader):\n",
    "            if args['gpu'] is not None:\n",
    "                data = data.cuda(args['gpu'], non_blocking=True).type(torch.float)\n",
    "                data = data.view(data.size(0), 1, data.size(2), data.size(1))\n",
    "            if torch.cuda.is_available():\n",
    "                label = label.cuda(args['gpu'], non_blocking=True).type(torch.float) ### although its a regression value but its called label following the source code from classification\n",
    "                mask  = mask.cuda(args['gpu'], non_blocking=True).type(torch.bool)\n",
    "\n",
    "            # compute output\n",
    "            output = model(data)\n",
    "            \n",
    "            out_flat = torch.masked_select(output.squeeze(), mask)\n",
    "            label_flat = torch.masked_select(label, mask)\n",
    "\n",
    "            loss = criterion(out_flat, label_flat)\n",
    "            \n",
    "            output_np = out_flat.detach().cpu().numpy().tolist()\n",
    "            target_np = label_flat.detach().cpu().numpy().tolist()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            # acc1 = accuracy(out_flat, label_flat, topk=(1, 1))\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            # top1.update(acc1[0], data.size(0))\n",
    "            \n",
    "            output_list += output_np\n",
    "            target_list += target_np\n",
    "            \n",
    "            # met_roc.update(roc, data.size(0))\n",
    "            # met_pr.update(pr, data.size(0))\n",
    "\n",
    "    return losses.avg, output_list, target_list\n",
    "\n",
    "def load_model(model_path, model_class, *model_args, **model_kwargs):\n",
    "    \"\"\"\n",
    "    Load the model from a saved state dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path: Path to the saved model state dictionary.\n",
    "    - model_class: The class of the model to instantiate.\n",
    "    - model_args: Positional arguments for the model class instantiation.\n",
    "    - model_kwargs: Keyword arguments for the model class instantiation.\n",
    "\n",
    "    Returns:\n",
    "    - model: The loaded model ready for prediction.\n",
    "    \"\"\"\n",
    "    # Instantiate the model\n",
    "    model = model_class(*model_args, **model_kwargs)\n",
    "    # Load the saved state dictionary\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "# def predict(test_loader, model, criterion, args):\n",
    "#     \"\"\"\n",
    "#     Predict the labels for the given data using the loaded model.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model: The loaded model ready for prediction.\n",
    "#     - data_loader: DataLoader for the dataset to predict on.\n",
    "\n",
    "#     Returns:\n",
    "#     - predictions: Predictions for the input data.\n",
    "#     \"\"\"\n",
    "#     predictions = []\n",
    "#     with torch.no_grad():  # No need to track gradients\n",
    "#         for data in test_loader:\n",
    "#             # Assuming your model expects data in a specific format, adjust accordingly\n",
    "#             if torch.cuda.is_available():\n",
    "#                 data = data.to('cuda')\n",
    "#             output = model(data)\n",
    "#             # Convert output to probabilities and then to the desired format\n",
    "#             # For example, using softmax for classification\n",
    "#             prob = torch.softmax(output, dim=1)\n",
    "#             predicted_classes = prob.argmax(dim=1)\n",
    "#             predictions.append(predicted_classes.cpu().numpy())  # Move to CPU and convert to numpy if needed\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbbabaa-9dd4-49ae-be54-909c542b649e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be saved in: saved_models/Kidney_Reg_attentionMSE_04.09 02:43\n",
      "Use GPU: 0 for training\n",
      "features / nodes 231 total time graphs 32 time series length 2016 classes 1\n",
      "Using cudnn.benchmark.\n",
      "****************************************************\n",
      "Dataset:  Kidney_Reg_attentionMSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN, epoch 0, train_loss 5.26772, train_MAE 1.69481, train_MSE 5.70603, train_R2S -1.02435\n",
      "VAL, epoch 0, val_loss 4.88847, val_MAE 1.50550, val_MSE 5.17434, val_R2S -0.73091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                       | 1/20 [04:13<1:20:07, 253.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, epoch 0, test_loss 4.13319, test_MAE 1.41514, test_MSE 4.63168, test_R2S -0.75068\n"
     ]
    }
   ],
   "source": [
    "main_work(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b51cb77-ecaa-48d1-8625-d397425b17f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58cefe-c901-4fbb-8fa2-e0a36b90e146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
