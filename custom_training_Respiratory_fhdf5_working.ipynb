{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9fc933-5024-468d-91bd-6408aa8297b9",
   "metadata": {},
   "source": [
    "![alt text](dynamic_metrics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a02078-96b3-4f14-9669-fb49f4edb4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be49837-23e5-418a-a1f6-aa834f8bb18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from loader import ICUVariableLengthLoaderTables, ICUVariableLengthDataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289ba758-e261-48fa-ac80-f8d81e62fce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'NVIDIA GeForce RTX 4060 Ti')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.is_available(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e40d61-adfc-430c-96e2-0a205a366cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c014230b-cda3-4cbc-920a-2d5b16570858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from net import GNNStack\n",
    "# from utils_todynet_binary import AverageMeter, accuracy, log_msg, get_default_train_val_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5d7406-8f67-45bd-add7-cb4a8fe7a97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a458334-b4e5-4c9b-bacb-976cb10ec9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=None, gamma=2):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         loss = (self.alpha[targets] * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "#         return loss\n",
    "\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=None, gamma=2, num_classes=None):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.gamma = gamma\n",
    "#         if alpha is None:\n",
    "#             self.alpha = None\n",
    "#         else:\n",
    "#             # If alpha is a single float number, expand it to a tensor\n",
    "#             if isinstance(alpha, float):\n",
    "#                 assert num_classes is not None, \"num_classes must be specified when alpha is a single float\"\n",
    "#                 self.alpha = torch.full((num_classes,), alpha)\n",
    "#             else:\n",
    "#                 self.alpha = alpha\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         if self.alpha is not None:\n",
    "#             if self.alpha.type() != inputs.data.type():\n",
    "#                 self.alpha = self.alpha.type_as(inputs.data)\n",
    "#             at = self.alpha[targets]\n",
    "#         else:\n",
    "#             at = 1.0\n",
    "#         loss = (at * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b608f5b7-259a-4fea-be59-b90be979c3b9",
   "metadata": {},
   "source": [
    "## aruguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e2de2d-8c0d-4ab8-8090-5e5621f13034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'arch': 'dyGIN2d', #what other models I can put here?? dyGCN2d, dyGIN2d\n",
    "    'dataset': 'Resp_failure', # \"AtrialFibrillation\" # 'Mortality', # 'MIMIC3'\n",
    "    'num_layers': 2,  # the number of GNN layers  3\n",
    "    'groups': 32,  # the number of time series groups (num_graphs)\n",
    "    'pool_ratio': 0.1,  # the ratio of pooling for nodes\n",
    "    'kern_size': [3,3],  # list of time conv kernel size for each layer [9,5,3]\n",
    "    'in_dim': 32,  # input dimensions of GNN stacks\n",
    "    'hidden_dim': 32,  # hidden dimensions of GNN stacks\n",
    "    'out_dim': 32,  # output dimensions of GNN stacks\n",
    "    'workers': 0,  # number of data loading workers\n",
    "    'epochs': 50,  # number of total epochs to run\n",
    "    'batch_size': 8,  # mini-batch size, this is the total batch size of all GPUs\n",
    "    'val_batch_size': 8,  # validation batch size\n",
    "    'lr': 0.001,  # initial learning rate\n",
    "    'weight_decay': 1e-4,  # weight decay\n",
    "    'evaluate': False,  # evaluate model on validation set\n",
    "    'seed': 2,  # seed for initializing training\n",
    "    'gpu': 0,  # GPU id to use\n",
    "    'use_benchmark': True,  # use benchmark\n",
    "    'tag': 'date',  # the tag for identifying the log and model files\n",
    "    'loss':'bce'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "982150c8-5c87-471b-b810-75f52df10c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"respfailure\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config=args\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c31c8a0-dcb1-4e0c-b44e-36bb9bd8f4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = TensorDataset(data_train, label_train)\n",
    "# val_dataset   = TensorDataset(data_val, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f6c801-7a9f-4f8a-9cbf-362febcf0683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=args['batch_size'],shuffle=True, num_workers=args['workers'], pin_memory=True)\n",
    "# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args['val_batch_size'], shuffle=False,num_workers=args['workers'],pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a648e31-70d5-4f32-b03a-6fd95b5211e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     # args = parser.parse_args()\n",
    "    \n",
    "#     # args.kern_size = [ int(l) for l in args.kern_size.split(\",\") ]\n",
    "\n",
    "#     # if args.seed is not None:\n",
    "#     random.seed(args['seed'])\n",
    "#     torch.manual_seed(args['seed'])\n",
    "\n",
    "#     main_work(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4c9a44f-2214-47c8-8de8-d47d7ba5202d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "              \n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        \n",
    "        # print(output, target)\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "           \n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "\n",
    "        return res\n",
    "\n",
    "def log_msg(message, log_file):\n",
    "    with open(log_file, 'a') as f:\n",
    "        print(message, file=f)\n",
    "\n",
    "\n",
    "def get_default_train_val_test_loader(args):\n",
    "\n",
    "    # get dataset-id\n",
    "    dsid = args['dataset']\n",
    "    h5_path= 'h5_folder/ml_stage_12h.h5'\n",
    "    # get dataset from .pt\n",
    "    # data_train  = torch.load(f'data/UCR/{dsid}/X_train.pt')\n",
    "    # data_val    = torch.load(f'data/UCR/{dsid}/X_valid.pt')\n",
    "    # data_val    = torch.load(f'data/UCR/{dsid}/X_test.pt')\n",
    "    \n",
    "    # label_train = torch.load(f'data/UCR/{dsid}/y_train.pt')\n",
    "    # label_val   = torch.load(f'data/UCR/{dsid}/y_valid.pt')\n",
    "    # label_val   = torch.load(f'data/UCR/{dsid}/y_test.pt')\n",
    "\n",
    "    # label_train = label_train.flatten().to(dtype=torch.int64)\n",
    "    # label_val   = label_val.flatten().to(dtype=torch.int64)\n",
    "    # init [num_variables, seq_length, num_classes]\n",
    "    \n",
    "    num_nodes = 231\n",
    "\n",
    "    # seq_length = 288\n",
    "    seq_length = 2016\n",
    "    \n",
    "    num_classes = 2\n",
    "\n",
    "\n",
    "    # convert data & labels to TensorDataset\n",
    "    # train_dataset = TensorDataset(data_train, label_train)\n",
    "    # val_dataset = TensorDataset(data_val, label_val)\n",
    "    \n",
    "    # task              = 'Mortality_At24Hours'\n",
    "#     maxlen            = 288                                                                             #patients| pos  | neg |\n",
    "#     data_loader_train = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='train') #10524   | 9613 | 911 |\n",
    "#     data_loader_val   = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='val')   #2205    | 2048 | 157 |\n",
    "#     data_loader_test  = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='test')  #2231    | 2045 | 186 |\n",
    "    \n",
    "    \n",
    "    \n",
    "    task   = 'Dynamic_RespFailure_12Hours' ##27249\n",
    "    maxlen            = 2016                                                                                   #|patients|    #-1 =8065                    #2016                      #difference\n",
    "    data_loader_train = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='train') #| 19092  |    5646423(3467116+2179307)     4776429(2901908+1874521)   869994(565208+304786)\n",
    "    data_loader_val   = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='val')   #| 4081   |    1220285(758822+461463)       1006329(614326+392003)     213956(144496+69460)\n",
    "    data_loader_test  = ICUVariableLengthDataset(source_path=h5_path, maxlen=maxlen, task=task, split='test')  #| 4076   |    1209724(753935+455789)       1015139(620532+394607)     194585(133403+61182)\n",
    "    \n",
    "    train_loader = DataLoader(data_loader_train, batch_size=4, shuffle=False, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "    # val_loader   = DataLoader(data_loader_val,   batch_size=256, shuffle=False, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "    val_loader  = DataLoader(data_loader_test,  batch_size=4, shuffle=False, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "    # test_loader  = DataLoader(data_loader_test,  batch_size=256, shuffle=False, num_workers=1,pin_memory=True, prefetch_factor=2)\n",
    "\n",
    "\n",
    "    # data_loader\n",
    "    # train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=args['batch_size'],shuffle=True,num_workers=args['workers'], pin_memory=True)\n",
    "    # val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=args['val_batch_size'],shuffle=False,num_workers=args['workers'],pin_memory=True)\n",
    "\n",
    "\n",
    "    return train_loader, val_loader, num_nodes, seq_length, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "991c1bc0-5e2d-4ea2-9691-3e2fac259bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main_work(args):\n",
    "    \n",
    "    random.seed(args['seed'])\n",
    "    torch.manual_seed(args['seed'])\n",
    "    \n",
    "    \n",
    "    # init acc\n",
    "    best_acc1 = 0\n",
    "    best_roc  = 0\n",
    "    best_pr   = 0\n",
    "    \n",
    "    if args['tag'] == 'date':\n",
    "        local_date = time.strftime('%m.%d %H:%M', time.localtime(time.time()))\n",
    "        args['tag'] = local_date\n",
    "\n",
    "    log_file = 'log/{}_gpu{}_{}_{}_exp.txt'.format(args['tag'], args['gpu'], args['arch'], args['dataset'])\n",
    "    \n",
    "    \n",
    "    if args['gpu'] is not None:\n",
    "        print(\"Use GPU: {} for training\".format(args['gpu']))\n",
    "\n",
    "\n",
    "    # dataset\n",
    "    train_loader, val_loader, num_nodes, seq_length, num_classes = get_default_train_val_test_loader(args)\n",
    "    \n",
    "    print('features / nodes', num_nodes,'total time graphs',seq_length,'classes', num_classes)\n",
    "    \n",
    "    # training model from net.py\n",
    "    model = GNNStack(gnn_model_type=args['arch'], num_layers=args['num_layers'], \n",
    "                     groups=args['groups'], pool_ratio=args['pool_ratio'], kern_size=args['kern_size'], \n",
    "                     in_dim=args['in_dim'], hidden_dim=args['hidden_dim'], out_dim=args['out_dim'], \n",
    "                     seq_len=seq_length, num_nodes=num_nodes, num_classes=num_classes)\n",
    "\n",
    "    # print & log\n",
    "    log_msg('epochs {}, lr {}, weight_decay {}'.format(args['epochs'], args['lr'], args['weight_decay']), log_file)\n",
    "    \n",
    "    log_msg(str(args), log_file)\n",
    "\n",
    "\n",
    "    # determine whether GPU or not\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"Warning! Using CPU!!!\")\n",
    "    elif args['gpu'] is not None:\n",
    "        torch.cuda.set_device(args['gpu'])\n",
    "\n",
    "        # collect cache\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model = model.cuda(args['gpu'])\n",
    "        if args['use_benchmark']:\n",
    "            cudnn.benchmark = True\n",
    "        print('Using cudnn.benchmark.')\n",
    "    else:\n",
    "        print(\"Error! We only have one gpu!!!\")\n",
    "\n",
    "\n",
    "    # define loss function(criterion) and optimizer\n",
    "    # class_weights = torch.tensor([0.087, 0.913], dtype=torch.float).cuda(args['gpu'])\n",
    "    # class_weights = torch.tensor([0.913, 0.087], dtype=torch.float).cuda(args['gpu'])\n",
    "    # class_weights = torch.tensor([1.0, 22.47], dtype=torch.float).cuda(args['gpu'])\n",
    "    \n",
    "    \n",
    "    # criterion = nn.CrossEntropyLoss(weight=class_weights).cuda(args['gpu'])\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().cuda(args['gpu'])\n",
    "    \n",
    "    # criterion = FocalLoss(gamma=0.1)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "    \n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    # validation\n",
    "    if args['evaluate']:\n",
    "        validate(val_loader, model, criterion, args)\n",
    "        return\n",
    "\n",
    "    # train & valid\n",
    "    print('****************************************************')\n",
    "    print('Dataset: ', args['dataset'])\n",
    "\n",
    "    dataset_time = AverageMeter('Time', ':6.3f')\n",
    "\n",
    "    loss_train = []\n",
    "    acc_train = []\n",
    "    loss_val = []\n",
    "    acc_val = []\n",
    "    epoches = []\n",
    "    \n",
    "    ###### 4 more lists to have values\n",
    "    roc_train = []\n",
    "    pr_train  = []\n",
    "    \n",
    "    roc_val   = []\n",
    "    pr_val    = []\n",
    "\n",
    "    end = time.time()\n",
    "    for epoch in tqdm(range(args['epochs'])):\n",
    "        epoches += [epoch]\n",
    "\n",
    "        # train for one epoch\n",
    "        acc_train_per, loss_train_per, output_train_per, target_train_per = train(train_loader, model, criterion, optimizer, lr_scheduler, args)\n",
    "        \n",
    "        acc_train += [acc_train_per]\n",
    "        loss_train += [loss_train_per]\n",
    "        # calculate metric\n",
    "        # print(len(target_train_per),len(output_train_per))\n",
    "        auc_roc_value_train = roc_auc_score(target_train_per, output_train_per)\n",
    "        auc_pr_value_train = average_precision_score(target_train_per, output_train_per)\n",
    "        #new code\n",
    "        roc_train += [auc_roc_value_train]\n",
    "        pr_train  += [auc_pr_value_train]\n",
    "\n",
    "        msg = f'TRAIN, epoch {epoch}, train_loss {loss_train_per}, train_acc {acc_train_per}, train_roc {auc_roc_value_train:.5f}, train_pr {auc_pr_value_train:.5f}'\n",
    "\n",
    "        print(f'TRAIN, epoch {epoch}, train_loss {loss_train_per:.5f}, train_roc {auc_roc_value_train:.5f}, train_pr {auc_pr_value_train:.5f}')\n",
    "        log_msg(msg, log_file)\n",
    "\n",
    "        \n",
    "        # evaluate on validation set\n",
    "        acc_val_per, loss_val_per, output_val_per, target_val_per = validate(val_loader, model, criterion, args)\n",
    "\n",
    "        acc_val  += [acc_val_per]\n",
    "        loss_val += [loss_val_per]\n",
    "        #calculate metric\n",
    "        # calculate metric\n",
    "        # print(len(target_val_per),len(output_val_per))\n",
    "        auc_roc_value_val = roc_auc_score(target_val_per, output_val_per)\n",
    "        auc_pr_value_val = average_precision_score(target_val_per, output_val_per)\n",
    "        #new code\n",
    "\n",
    "        msg = f'VAL, epoch {epoch}, val_loss {loss_val_per}, val_acc {acc_val_per}, val_roc {auc_roc_value_val:.5f}, val_pr {auc_pr_value_val:.5f}'\n",
    "        \n",
    "        print(f'VAL, epoch {epoch}, val_loss {loss_val_per:.5f}, val_roc {auc_roc_value_val:.5f}, val_pr {auc_pr_value_val:.5f}')\n",
    "        log_msg(msg, log_file)\n",
    "\n",
    "        \n",
    "        \n",
    "        # remember best acc\n",
    "        best_acc1 = max(acc_val_per, best_acc1)\n",
    "        \n",
    "        best_roc = max(auc_roc_value_val, best_roc)\n",
    "        \n",
    "        best_pr  = max(auc_pr_value_val, best_pr)\n",
    "        \n",
    "    #     wandb.log({\"train_loss\": loss_train_per, \"train_roc\": auc_roc_value_train, \"train_pr\": auc_pr_value_train, \\\n",
    "    #                \"val_loss\": loss_val_per, \"val_roc\": auc_roc_value_val, \"val_pr\": auc_pr_value_val, \"best_val_roc\": best_roc, \"best_val_pr\": best_pr})\n",
    "    # wandb.finish()\n",
    "    # measure elapsed time\n",
    "    dataset_time.update(time.time() - end)\n",
    "\n",
    "    # log & print the best_acc\n",
    "    msg = f'\\n\\n * BEST_ACC: {best_acc1}\\n * TIME: {dataset_time}\\n'\n",
    "    log_msg(msg, log_file)\n",
    "\n",
    "    print(f' * best_acc1: {best_acc1}, best_roc: {best_roc}, best_pr: {best_pr}')\n",
    "    print(f' * time: {dataset_time}')\n",
    "    print('****************************************************')\n",
    "\n",
    "\n",
    "    # collect cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, lr_scheduler, args):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc', ':6.2f')\n",
    "    # met_roc = AverageMeter('ROC', ':6.2f')\n",
    "    # met_pr = AverageMeter('PR', ':6.2f')\n",
    "    \n",
    "    output_list = []\n",
    "    target_list = [] \n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for count, (data, label, mask) in enumerate(train_loader):\n",
    "\n",
    "        # data in cuda\n",
    "        data = data.cuda(args['gpu']).type(torch.float)\n",
    "        data = data.view(data.size(0), 1, data.size(2), data.size(1))\n",
    "        mask = mask.cuda(args['gpu']).type(torch.bool)\n",
    "        label = label.cuda(args['gpu']).type(torch.long)\n",
    "\n",
    "        # compute output\n",
    "        output = model(data)\n",
    "        # print(len(output))\n",
    "        # print('output', output.shape, 'mask', mask.shape)\n",
    "        out_flat = torch.masked_select(output, mask.unsqueeze(-1)).reshape(-1, output.shape[-1])\n",
    "        # print(output)\n",
    "        # print(output.shape, mask.shape, out_flat.shape)\n",
    "        # break\n",
    "        # out_flat = torch.masked_select(output[:,:,1], mask)\n",
    "        \n",
    "\n",
    "        label_flat = torch.masked_select(label, mask)\n",
    "        # print('output',output.shape, 'mask', mask.shape,'out_flat', out_flat.shape, 'label', label.shape, 'label_flat', label_flat.shape)\n",
    "        loss = criterion(out_flat, label_flat)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1 = accuracy(out_flat, label_flat, topk=(1, 1))\n",
    "        \n",
    "        output_np = torch.softmax(out_flat, dim=1).detach().cpu().numpy()[:,1].tolist()\n",
    "        \n",
    "        target_np = label_flat.detach().cpu().numpy().tolist()\n",
    "        \n",
    "        # print(output_np, target_np)\n",
    "        \n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        top1.update(acc1[0], data.size(0))\n",
    "        \n",
    "        # met_roc.update(roc, data.size(0))\n",
    "        # met_pr.update(pr, data.size(0))\n",
    "        output_list += output_np\n",
    "        target_list += target_np\n",
    "\n",
    "        # compute gradient and do Adam step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    lr_scheduler.step(top1.avg)\n",
    "\n",
    "    return top1.avg, losses.avg, output_list, target_list\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, args):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # met_roc = AverageMeter('ROC', ':6.2f')\n",
    "    # met_pr = AverageMeter('PR', ':6.2f')\n",
    "    output_list = []\n",
    "    target_list = [] \n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for count, (data, label, mask) in enumerate(val_loader):\n",
    "            if args['gpu'] is not None:\n",
    "                data = data.cuda(args['gpu'], non_blocking=True).type(torch.float)\n",
    "                data = data.view(data.size(0), 1, data.size(2), data.size(1))\n",
    "            if torch.cuda.is_available():\n",
    "                label = label.cuda(args['gpu'], non_blocking=True).type(torch.long)\n",
    "                mask  = mask.cuda(args['gpu'], non_blocking=True).type(torch.bool)\n",
    "\n",
    "            # compute output\n",
    "            output = model(data)\n",
    "            \n",
    "            out_flat = torch.masked_select(output, mask.unsqueeze(-1)).reshape(-1, output.shape[-1])\n",
    "            label_flat = torch.masked_select(label, mask)\n",
    "\n",
    "            loss = criterion(out_flat, label_flat)\n",
    "            \n",
    "            output_np = torch.softmax(out_flat, dim=1).detach().cpu().numpy()[:,1].tolist()\n",
    "            target_np = label_flat.detach().cpu().numpy().tolist()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1 = accuracy(out_flat, label_flat, topk=(1, 1))\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            top1.update(acc1[0], data.size(0))\n",
    "            \n",
    "            output_list += output_np\n",
    "            target_list += target_np\n",
    "            \n",
    "            # met_roc.update(roc, data.size(0))\n",
    "            # met_pr.update(pr, data.size(0))\n",
    "\n",
    "    return top1.avg, losses.avg, output_list, target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "265cb92e-c573-4e83-a10e-791712ca78d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: 0 for training\n",
      "features / nodes 231 total time graphs 2016 classes 2\n",
      "Using cudnn.benchmark.\n",
      "****************************************************\n",
      "Dataset:  Resp_failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN, epoch 0, train_loss 0.68530, train_roc 0.54358, train_pr 0.42628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                      | 1/50 [24:28<19:58:59, 1468.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL, epoch 0, val_loss 0.68367, val_roc 0.54428, val_pr 0.42648\n",
      "TRAIN, epoch 1, train_loss 0.68408, train_roc 0.54894, train_pr 0.43311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 2/50 [48:52<19:32:45, 1465.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL, epoch 1, val_loss 0.68445, val_roc 0.53736, val_pr 0.42070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                     | 2/50 [50:16<20:06:26, 1508.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main_work(args)\n",
      "Cell \u001b[0;32mIn[14], line 103\u001b[0m, in \u001b[0;36mmain_work\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    100\u001b[0m epoches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [epoch]\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m acc_train_per, loss_train_per, output_train_per, target_train_per \u001b[38;5;241m=\u001b[39m train(train_loader, model, criterion, optimizer, lr_scheduler, args)\n\u001b[1;32m    105\u001b[0m acc_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [acc_train_per]\n\u001b[1;32m    106\u001b[0m loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [loss_train_per]\n",
      "Cell \u001b[0;32mIn[14], line 182\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, lr_scheduler, args)\u001b[0m\n\u001b[1;32m    177\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m count, (data, label, mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    180\u001b[0m \n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# data in cuda\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcuda(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    183\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m, data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m), data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    184\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mcuda(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mbool)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main_work(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7b3fb-cdbe-463e-9930-3e07a5d373a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO ignite metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b77c3-2735-4cb4-b2df-515ec8cdf3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
