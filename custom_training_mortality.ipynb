{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb5c854-b0a4-435f-9108-df7329b3dd51",
   "metadata": {
    "tags": []
   },
   "source": [
    "![alt text](metrics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a02078-96b3-4f14-9669-fb49f4edb4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import wandb\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289ba758-e261-48fa-ac80-f8d81e62fce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'NVIDIA GeForce GTX 1650')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.is_available(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c014230b-cda3-4cbc-920a-2d5b16570858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from net import GNNStack\n",
    "from utils_todynet import AverageMeter, accuracy, log_msg, get_default_train_val_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5d7406-8f67-45bd-add7-cb4a8fe7a97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a458334-b4e5-4c9b-bacb-976cb10ec9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=None, gamma=2):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         loss = (self.alpha[targets] * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "#         return loss\n",
    "\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, alpha=None, gamma=2, num_classes=None):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.gamma = gamma\n",
    "#         if alpha is None:\n",
    "#             self.alpha = None\n",
    "#         else:\n",
    "#             # If alpha is a single float number, expand it to a tensor\n",
    "#             if isinstance(alpha, float):\n",
    "#                 assert num_classes is not None, \"num_classes must be specified when alpha is a single float\"\n",
    "#                 self.alpha = torch.full((num_classes,), alpha)\n",
    "#             else:\n",
    "#                 self.alpha = alpha\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         if self.alpha is not None:\n",
    "#             if self.alpha.type() != inputs.data.type():\n",
    "#                 self.alpha = self.alpha.type_as(inputs.data)\n",
    "#             at = self.alpha[targets]\n",
    "#         else:\n",
    "#             at = 1.0\n",
    "#         loss = (at * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b608f5b7-259a-4fea-be59-b90be979c3b9",
   "metadata": {},
   "source": [
    "## aruguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e2de2d-8c0d-4ab8-8090-5e5621f13034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'arch': 'dyGIN2d', #what other models I can put here?? dyGCN2d, dyGIN2d\n",
    "    'dataset': 'Mortality', # \"AtrialFibrillation\" # 'Mortality', # 'MIMIC3'\n",
    "    'num_layers': 2,  # the number of GNN layers  3\n",
    "    'groups': 16,  # the number of time series groups (num_graphs)\n",
    "    'pool_ratio': 0.1,  # the ratio of pooling for nodes\n",
    "    'kern_size': [3,3],  # list of time conv kernel size for each layer [9,5,3]\n",
    "    'in_dim': 32,  # input dimensions of GNN stacks\n",
    "    'hidden_dim': 32,  # hidden dimensions of GNN stacks\n",
    "    'out_dim': 32,  # output dimensions of GNN stacks\n",
    "    'workers': 4,  # number of data loading workers\n",
    "    'epochs': 30,  # number of total epochs to run\n",
    "    'batch_size': 4,  # mini-batch size, this is the total batch size of all GPUs\n",
    "    'val_batch_size': 4,  # validation batch size\n",
    "    'lr': 0.000095,  # initial learning rate\n",
    "    'weight_decay': 1e-4,  # weight decay\n",
    "    'evaluate': False,  # evaluate model on validation set\n",
    "    'seed': 2,  # seed for initializing training\n",
    "    'gpu': 0,  # GPU id to use\n",
    "    'use_benchmark': True,  # use benchmark\n",
    "    'tag': 'date',  # the tag for identifying the log and model files\n",
    "    'loss':'bce'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982150c8-5c87-471b-b810-75f52df10c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"mortality\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config=args\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c31c8a0-dcb1-4e0c-b44e-36bb9bd8f4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = TensorDataset(data_train, label_train)\n",
    "# val_dataset   = TensorDataset(data_val, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f6c801-7a9f-4f8a-9cbf-362febcf0683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=args['batch_size'],shuffle=True, num_workers=args['workers'], pin_memory=True)\n",
    "# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args['val_batch_size'], shuffle=False,num_workers=args['workers'],pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a648e31-70d5-4f32-b03a-6fd95b5211e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     # args = parser.parse_args()\n",
    "    \n",
    "#     # args.kern_size = [ int(l) for l in args.kern_size.split(\",\") ]\n",
    "\n",
    "#     # if args.seed is not None:\n",
    "#     random.seed(args['seed'])\n",
    "#     torch.manual_seed(args['seed'])\n",
    "\n",
    "#     main_work(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "991c1bc0-5e2d-4ea2-9691-3e2fac259bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main_work(args):\n",
    "    \n",
    "    random.seed(args['seed'])\n",
    "    torch.manual_seed(args['seed'])\n",
    "    \n",
    "    \n",
    "    # init acc\n",
    "    best_acc1 = 0\n",
    "    best_roc  = 0\n",
    "    best_pr   = 0\n",
    "    \n",
    "    if args['tag'] == 'date':\n",
    "        local_date = time.strftime('%m.%d %H:%M', time.localtime(time.time()))\n",
    "        args['tag'] = local_date\n",
    "\n",
    "    # Use the 'tag' which now contains either the date or a custom tag along with the dataset name for the directory\n",
    "    run_dir_name = f\"{args['dataset']}_{args['tag']}\"\n",
    "    \n",
    "    # Base directory for saving models\n",
    "    base_model_save_dir = \"saved_models\"\n",
    "    \n",
    "    # Specific directory for this run\n",
    "    specific_model_save_dir = os.path.join(base_model_save_dir, run_dir_name)\n",
    "    os.makedirs(specific_model_save_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Models will be saved in: {specific_model_save_dir}\")\n",
    "\n",
    "    log_file = 'log/{}_gpu{}_{}_{}_exp.txt'.format(args['tag'], args['gpu'], args['arch'], args['dataset'])\n",
    "    \n",
    "    \n",
    "    if args['gpu'] is not None:\n",
    "        print(\"Use GPU: {} for training\".format(args['gpu']))\n",
    "\n",
    "\n",
    "    # dataset\n",
    "    train_loader, val_loader, num_nodes, seq_length, num_classes = get_default_train_val_test_loader(args)\n",
    "    \n",
    "    print('features / nodes', num_nodes,'total time graphs',seq_length,'classes', num_classes)\n",
    "    \n",
    "    # training model from net.py\n",
    "    model = GNNStack(gnn_model_type=args['arch'], num_layers=args['num_layers'], \n",
    "                     groups=args['groups'], pool_ratio=args['pool_ratio'], kern_size=args['kern_size'], \n",
    "                     in_dim=args['in_dim'], hidden_dim=args['hidden_dim'], out_dim=args['out_dim'], \n",
    "                     seq_len=seq_length, num_nodes=num_nodes, num_classes=num_classes)\n",
    "\n",
    "    # print & log\n",
    "    log_msg('epochs {}, lr {}, weight_decay {}'.format(args['epochs'], args['lr'], args['weight_decay']), log_file)\n",
    "    \n",
    "    log_msg(str(args), log_file)\n",
    "\n",
    "\n",
    "    # determine whether GPU or not\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"Warning! Using CPU!!!\")\n",
    "    elif args['gpu'] is not None:\n",
    "        torch.cuda.set_device(args['gpu'])\n",
    "\n",
    "        # collect cache\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        model = model.cuda(args['gpu'])\n",
    "        if args['use_benchmark']:\n",
    "            cudnn.benchmark = True\n",
    "        print('Using cudnn.benchmark.')\n",
    "    else:\n",
    "        print(\"Error! We only have one gpu!!!\")\n",
    "\n",
    "\n",
    "    # define loss function(criterion) and optimizer\n",
    "    # class_weights = torch.tensor([0.087, 0.913], dtype=torch.float).cuda(args['gpu'])\n",
    "    # class_weights = torch.tensor([0.913, 0.087], dtype=torch.float).cuda(args['gpu'])\n",
    "    # class_weights = torch.tensor([1.0, 22.47], dtype=torch.float).cuda(args['gpu'])\n",
    "    \n",
    "    \n",
    "    # criterion = nn.CrossEntropyLoss(weight=class_weights).cuda(args['gpu'])\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().cuda(args['gpu'])\n",
    "    \n",
    "    # criterion = FocalLoss(gamma=0.1)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "    \n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "    # validation\n",
    "    if args['evaluate']:\n",
    "        validate(val_loader, model, criterion, args)\n",
    "        return\n",
    "\n",
    "    # train & valid\n",
    "    print('****************************************************')\n",
    "    print('Dataset: ', args['dataset'])\n",
    "\n",
    "    dataset_time = AverageMeter('Time', ':6.3f')\n",
    "\n",
    "    loss_train = []\n",
    "    acc_train = []\n",
    "    loss_val = []\n",
    "    acc_val = []\n",
    "    epoches = []\n",
    "    \n",
    "    ###### 4 more lists to have values\n",
    "    roc_train = []\n",
    "    pr_train  = []\n",
    "    \n",
    "    roc_val   = []\n",
    "    pr_val    = []\n",
    "\n",
    "    end = time.time()\n",
    "    for epoch in tqdm(range(args['epochs'])):\n",
    "        epoches += [epoch]\n",
    "\n",
    "        # train for one epoch\n",
    "        acc_train_per, loss_train_per, output_train_per, target_train_per = train(train_loader, model, criterion, optimizer, lr_scheduler, args)\n",
    "        \n",
    "        acc_train += [acc_train_per]\n",
    "        loss_train += [loss_train_per]\n",
    "        # calculate metric\n",
    "        # print(len(target_train_per),len(output_train_per))\n",
    "        auc_roc_value_train = roc_auc_score(target_train_per, output_train_per)\n",
    "        auc_pr_value_train = average_precision_score(target_train_per, output_train_per)\n",
    "        #new code\n",
    "        roc_train += [auc_roc_value_train]\n",
    "        pr_train  += [auc_pr_value_train]\n",
    "\n",
    "        msg = f'TRAIN, epoch {epoch}, train_loss {loss_train_per}, train_acc {acc_train_per}, train_roc {auc_roc_value_train:.5f}, train_pr {auc_pr_value_train:.5f}'\n",
    "\n",
    "        print(f'TRAIN, epoch {epoch}, train_loss {loss_train_per:.5f}, train_roc {auc_roc_value_train:.5f}, train_pr {auc_pr_value_train:.5f}')\n",
    "        log_msg(msg, log_file)\n",
    "\n",
    "        \n",
    "        # evaluate on validation set\n",
    "        acc_val_per, loss_val_per, output_val_per, target_val_per = validate(val_loader, model, criterion, args)\n",
    "\n",
    "        acc_val  += [acc_val_per]\n",
    "        loss_val += [loss_val_per]\n",
    "        #calculate metric\n",
    "        # calculate metric\n",
    "        # print(len(target_val_per),len(output_val_per))\n",
    "        auc_roc_value_val = roc_auc_score(target_val_per, output_val_per)\n",
    "        auc_pr_value_val = average_precision_score(target_val_per, output_val_per)\n",
    "        #new code\n",
    "\n",
    "        msg = f'VAL, epoch {epoch}, val_loss {loss_val_per}, val_acc {acc_val_per}, val_roc {auc_roc_value_val:.5f}, val_pr {auc_pr_value_val:.5f}'\n",
    "        \n",
    "        print(f'VAL, epoch {epoch}, val_loss {loss_val_per:.5f}, val_roc {auc_roc_value_val:.5f}, val_pr {auc_pr_value_val:.5f}')\n",
    "        log_msg(msg, log_file)\n",
    "\n",
    "        \n",
    "        \n",
    "        # remember best acc\n",
    "        best_acc1 = max(acc_val_per, best_acc1)\n",
    "        \n",
    "        best_roc = max(auc_roc_value_val, best_roc)\n",
    "        \n",
    "        best_pr  = max(auc_pr_value_val, best_pr)\n",
    "        \n",
    "#         wandb.log({\"train_loss\": loss_train_per, \"train_roc\": auc_roc_value_train, \"train_pr\": auc_pr_value_train, \\\n",
    "#                    \"val_loss\": loss_val_per, \"val_roc\": auc_roc_value_val, \"val_pr\": auc_pr_value_val, \"best_val_roc\": best_roc, \"best_val_pr\": best_pr})\n",
    "#     wandb.finish()\n",
    "        # Construct the filename with metrics\n",
    "        acc_val_per_scalar = acc_val_per.item() if isinstance(acc_val_per, torch.Tensor) else acc_val_per\n",
    "        auc_roc_value_val_scalar = auc_roc_value_val.item() if isinstance(auc_roc_value_val, torch.Tensor) else auc_roc_value_val\n",
    "        auc_pr_value_val_scalar = auc_pr_value_val.item() if isinstance(auc_pr_value_val, torch.Tensor) else auc_pr_value_val\n",
    "        \n",
    "        # Now use these scalar values in the filename\n",
    "        filename = f\"model_epoch_{epoch}_acc_{acc_val_per_scalar:.3f}_roc_{auc_roc_value_val_scalar:.3f}_pr_{auc_pr_value_val_scalar:.3f}.pth\"\n",
    "        \n",
    "        # Continue with the existing logic to save the model\n",
    "        model_path = os.path.join(specific_model_save_dir, filename)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # measure elapsed time\n",
    "    dataset_time.update(time.time() - end)\n",
    "\n",
    "    # log & print the best_acc\n",
    "    msg = f'\\n\\n * BEST_ACC: {best_acc1}\\n * TIME: {dataset_time}\\n'\n",
    "    log_msg(msg, log_file)\n",
    "\n",
    "    print(f' * best_acc1: {best_acc1}, best_roc: {best_roc}, best_pr: {best_pr}')\n",
    "    print(f' * time: {dataset_time}')\n",
    "    print('****************************************************')\n",
    "\n",
    "\n",
    "    # collect cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, lr_scheduler, args):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc', ':6.2f')\n",
    "    # met_roc = AverageMeter('ROC', ':6.2f')\n",
    "    # met_pr = AverageMeter('PR', ':6.2f')\n",
    "    \n",
    "    output_list = []\n",
    "    target_list = [] \n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for count, (data, label) in enumerate(train_loader):\n",
    "\n",
    "        # data in cuda\n",
    "        data = data.cuda(args['gpu']).type(torch.float)\n",
    "        label = label.cuda(args['gpu']).type(torch.long)\n",
    "\n",
    "        # compute output\n",
    "        output = model(data)\n",
    "    \n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1 = accuracy(output, label, topk=(1, 1))\n",
    "        \n",
    "        output_np = torch.softmax(output, dim=1).detach().cpu().numpy()[:,1].tolist()\n",
    "        \n",
    "        target_np = label.detach().cpu().numpy().tolist()\n",
    "        \n",
    "        # print(output_np, target_np)\n",
    "        \n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        top1.update(acc1[0], data.size(0))\n",
    "        \n",
    "        # met_roc.update(roc, data.size(0))\n",
    "        # met_pr.update(pr, data.size(0))\n",
    "        output_list += output_np\n",
    "        target_list += target_np\n",
    "\n",
    "        # compute gradient and do Adam step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    lr_scheduler.step(top1.avg)\n",
    "\n",
    "    return top1.avg, losses.avg, output_list, target_list\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, args):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # met_roc = AverageMeter('ROC', ':6.2f')\n",
    "    # met_pr = AverageMeter('PR', ':6.2f')\n",
    "    output_list = []\n",
    "    target_list = [] \n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for count, (data, label) in enumerate(val_loader):\n",
    "            if args['gpu'] is not None:\n",
    "                data = data.cuda(args['gpu'], non_blocking=True).type(torch.float)\n",
    "            if torch.cuda.is_available():\n",
    "                label = label.cuda(args['gpu'], non_blocking=True).type(torch.long)\n",
    "\n",
    "            # compute output\n",
    "            output = model(data)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            output_np = torch.softmax(output, dim=1).detach().cpu().numpy()[:,1].tolist()\n",
    "            target_np = label.detach().cpu().numpy().tolist()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1 = accuracy(output, label, topk=(1, 1))\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            top1.update(acc1[0], data.size(0))\n",
    "            \n",
    "            output_list += output_np\n",
    "            target_list += target_np\n",
    "            \n",
    "            # met_roc.update(roc, data.size(0))\n",
    "            # met_pr.update(pr, data.size(0))\n",
    "\n",
    "    return top1.avg, losses.avg, output_list, target_list\n",
    "\n",
    "def load_model(model_path, model_class, *model_args, **model_kwargs):\n",
    "    \"\"\"\n",
    "    Load the model from a saved state dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path: Path to the saved model state dictionary.\n",
    "    - model_class: The class of the model to instantiate.\n",
    "    - model_args: Positional arguments for the model class instantiation.\n",
    "    - model_kwargs: Keyword arguments for the model class instantiation.\n",
    "\n",
    "    Returns:\n",
    "    - model: The loaded model ready for prediction.\n",
    "    \"\"\"\n",
    "    # Instantiate the model\n",
    "    model = model_class(*model_args, **model_kwargs)\n",
    "    # Load the saved state dictionary\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "def predict(model, data_loader):\n",
    "    \"\"\"\n",
    "    Predict the labels for the given data using the loaded model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The loaded model ready for prediction.\n",
    "    - data_loader: DataLoader for the dataset to predict on.\n",
    "\n",
    "    Returns:\n",
    "    - predictions: Predictions for the input data.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    with torch.no_grad():  # No need to track gradients\n",
    "        for data in data_loader:\n",
    "            # Assuming your model expects data in a specific format, adjust accordingly\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.to('cuda')\n",
    "            output = model(data)\n",
    "            # Convert output to probabilities and then to the desired format\n",
    "            # For example, using softmax for classification\n",
    "            prob = torch.softmax(output, dim=1)\n",
    "            predicted_classes = prob.argmax(dim=1)\n",
    "            predictions.append(predicted_classes.cpu().numpy())  # Move to CPU and convert to numpy if needed\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "265cb92e-c573-4e83-a10e-791712ca78d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be saved in: saved_models/Mortality_02.19 19:10\n",
      "Use GPU: 0 for training\n",
      "features / nodes 231 total time graphs 288 classes 2\n",
      "Using cudnn.benchmark.\n",
      "****************************************************\n",
      "Dataset:  Mortality\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fb96166f5940c787a1d4d15c41aaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN, epoch 0, train_loss 0.30024, train_roc 0.67835, train_pr 0.16221\n",
      "VAL, epoch 0, val_loss 0.21855, val_roc 0.87050, val_pr 0.41038\n",
      "TRAIN, epoch 1, train_loss 0.22894, train_roc 0.83433, train_pr 0.38487\n",
      "VAL, epoch 1, val_loss 0.20015, val_roc 0.87927, val_pr 0.48147\n",
      "TRAIN, epoch 2, train_loss 0.21301, train_roc 0.86105, train_pr 0.44842\n",
      "VAL, epoch 2, val_loss 0.19571, val_roc 0.88772, val_pr 0.55788\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main_work(args)\n",
      "Cell \u001b[0;32mIn[11], line 115\u001b[0m, in \u001b[0;36mmain_work\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    112\u001b[0m epoches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [epoch]\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m acc_train_per, loss_train_per, output_train_per, target_train_per \u001b[38;5;241m=\u001b[39m train(train_loader, model, criterion, optimizer, lr_scheduler, args)\n\u001b[1;32m    117\u001b[0m acc_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [acc_train_per]\n\u001b[1;32m    118\u001b[0m loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [loss_train_per]\n",
      "Cell \u001b[0;32mIn[11], line 206\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, lr_scheduler, args)\u001b[0m\n\u001b[1;32m    201\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m count, (data, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    204\u001b[0m \n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# data in cuda\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcuda(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    207\u001b[0m     label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mcuda(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# compute output\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main_work(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3c7f07f-e609-4c5f-a0fb-ae1c1f0cd898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ae47b68-9e0b-4989-8f21-89749ee39de4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GNNStack.__init__() missing 11 required positional arguments: 'gnn_model_type', 'num_layers', 'groups', 'pool_ratio', 'kern_size', 'in_dim', 'hidden_dim', 'out_dim', 'seq_len', 'num_nodes', and 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_models/Mortality_02.19 19:10/model_epoch_2_acc_92.604_roc_0.888_pr_0.558.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(model_path, GNNStack)\n",
      "Cell \u001b[0;32mIn[11], line 293\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path, model_class, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03mLoad the model from a saved state dictionary.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m- model: The loaded model ready for prediction.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Instantiate the model\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m model \u001b[38;5;241m=\u001b[39m model_class(\u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Load the saved state dictionary\u001b[39;00m\n\u001b[1;32m    295\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path))\n",
      "\u001b[0;31mTypeError\u001b[0m: GNNStack.__init__() missing 11 required positional arguments: 'gnn_model_type', 'num_layers', 'groups', 'pool_ratio', 'kern_size', 'in_dim', 'hidden_dim', 'out_dim', 'seq_len', 'num_nodes', and 'num_classes'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "model_path = 'saved_models/Mortality_02.19 19:10/model_epoch_2_acc_92.604_roc_0.888_pr_0.558.pth'\n",
    "model = load_model(model_path, GNNStack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee5b71-df18-40ce-8306-46d25381df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "train_loader, val_loader, num_nodes, seq_length, num_classes = get_default_train_val_test_loader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a04268a-6e56-4c9a-af62-ef7a51a2c51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b59bea-155e-48ff-ad28-144da52e2b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d89b1-02ae-4bde-855d-9a7afb3fb29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de46b36-bbed-4648-b307-08e36812fa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd294a-20b3-4102-a719-ad53f428a282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b77c3-2735-4cb4-b2df-515ec8cdf3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
