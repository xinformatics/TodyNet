{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a108eb2-3abe-4428-9c19-15ab24ffd075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from torch.nn import init\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4976f45f-897c-4d75-893a-61d228575f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21a7c7-3661-44d0-990f-2e5174401840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_shallow_embedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_nodes, k_neighs, num_graphs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_nodes = num_nodes\n",
    "        self.k = k_neighs\n",
    "        self.num_graphs = num_graphs\n",
    "\n",
    "        self.emb_s = Parameter(Tensor(num_graphs, num_nodes, 1))\n",
    "        self.emb_t = Parameter(Tensor(num_graphs, 1, num_nodes))\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        init.xavier_uniform_(self.emb_s)\n",
    "        init.xavier_uniform_(self.emb_t)\n",
    "        \n",
    "        \n",
    "    def forward(self, device):\n",
    "        \n",
    "        # adj: [G, N, N]\n",
    "        adj = torch.matmul(self.emb_s, self.emb_t).to(device)\n",
    "        \n",
    "        # remove self-loop\n",
    "        adj = adj.clone()\n",
    "        idx = torch.arange(self.num_nodes, dtype=torch.long, device=device)\n",
    "        adj[:, idx, idx] = float('-inf')\n",
    "        \n",
    "        # top-k-edge adj\n",
    "        adj_flat = adj.reshape(self.num_graphs, -1)\n",
    "        indices = adj_flat.topk(k=self.k)[1].reshape(-1)\n",
    "        \n",
    "        idx = torch.tensor([ i//self.k for i in range(indices.size(0)) ], device=device)\n",
    "        \n",
    "        adj_flat = torch.zeros_like(adj_flat).clone()\n",
    "        adj_flat[idx, indices] = 1.\n",
    "        adj = adj_flat.reshape_as(adj)\n",
    "        \n",
    "        return adj\n",
    "\n",
    "class Group_Linear(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, groups=1, bias=False):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.out_channels = out_channels\n",
    "        self.groups = groups\n",
    "        \n",
    "        self.group_mlp = nn.Conv2d(in_channels * groups, out_channels * groups, kernel_size=(1, 1), groups=groups, bias=bias)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.group_mlp.reset_parameters()\n",
    "        \n",
    "        \n",
    "    def forward(self, x: Tensor, is_reshape: False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F] (if not is_reshape), [B, C, G, N, F//G] (if is_reshape)\n",
    "        \"\"\"\n",
    "        B = x.size(0)\n",
    "        C = x.size(1)\n",
    "        N = x.size(-2)\n",
    "        G = self.groups\n",
    "        \n",
    "        if not is_reshape:\n",
    "            # x: [B, C_in, G, N, F//G]\n",
    "            x = x.reshape(B, C, N, G, -1).transpose(2, 3)\n",
    "        # x: [B, G*C_in, N, F//G]\n",
    "        x = x.transpose(1, 2).reshape(B, G*C, N, -1)\n",
    "        \n",
    "        out = self.group_mlp(x)\n",
    "        out = out.reshape(B, G, self.out_channels, N, -1).transpose(1, 2)\n",
    "        \n",
    "        # out: [B, C_out, G, N, F//G]\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseGCNConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, groups=1, bias=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.lin = Group_Linear(in_channels, out_channels, groups, bias=False)\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        init.zeros_(self.bias)\n",
    "        \n",
    "    def norm(self, adj: Tensor, add_loop):\n",
    "        if add_loop:\n",
    "            adj = adj.clone()\n",
    "            idx = torch.arange(adj.size(-1), dtype=torch.long, device=adj.device)\n",
    "            adj[:, idx, idx] += 1\n",
    "        \n",
    "        deg_inv_sqrt = adj.sum(-1).clamp(min=1).pow(-0.5)\n",
    "        \n",
    "        adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n",
    "        \n",
    "        return adj\n",
    "        \n",
    "        \n",
    "    def forward(self, x: Tensor, adj: Tensor, add_loop=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F]\n",
    "            adj (Tensor): [B, G, N, N]\n",
    "        \"\"\"\n",
    "        adj = self.norm(adj, add_loop).unsqueeze(1)\n",
    "\n",
    "        # x: [B, C, G, N, F//G]\n",
    "        x = self.lin(x, False)\n",
    "        \n",
    "        out = torch.matmul(adj, x)\n",
    "        \n",
    "        # out: [B, C, N, F]\n",
    "        B, C, _, N, _ = out.size()\n",
    "        out = out.transpose(2, 3).reshape(B, C, N, -1)\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            out = out.transpose(1, -1) + self.bias\n",
    "            out = out.transpose(1, -1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseGINConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, groups=1, eps=0, train_eps=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TODO: Multi-layer model\n",
    "        self.mlp = Group_Linear(in_channels, out_channels, groups, bias=False)\n",
    "        \n",
    "        self.init_eps = eps\n",
    "        if train_eps:\n",
    "            self.eps = Parameter(Tensor([eps]))\n",
    "        else:\n",
    "            self.register_buffer('eps', Tensor([eps]))\n",
    "            \n",
    "        self.reset_parameters()\n",
    "            \n",
    "    def reset_parameters(self):\n",
    "        self.mlp.reset_parameters()\n",
    "        self.eps.data.fill_(self.init_eps)\n",
    "        \n",
    "    def norm(self, adj: Tensor, add_loop):\n",
    "        if add_loop:\n",
    "            adj = adj.clone()\n",
    "            idx = torch.arange(adj.size(-1), dtype=torch.long, device=adj.device)\n",
    "            adj[..., idx, idx] += 1\n",
    "        \n",
    "        deg_inv_sqrt = adj.sum(-1).clamp(min=1).pow(-0.5)\n",
    "        \n",
    "        adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n",
    "        \n",
    "        return adj\n",
    "        \n",
    "        \n",
    "    def forward(self, x: Tensor, adj: Tensor, add_loop=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F]\n",
    "            adj (Tensor): [G, N, N]\n",
    "        \"\"\"\n",
    "        B, C, N, _ = x.size()\n",
    "        G = adj.size(0)\n",
    "        \n",
    "        # adj-norm\n",
    "        adj = self.norm(adj, add_loop=False)\n",
    "        \n",
    "        # x: [B, C, G, N, F//G]\n",
    "        x = x.reshape(B, C, N, G, -1).transpose(2, 3)\n",
    "        \n",
    "        out = torch.matmul(adj, x)\n",
    "        \n",
    "        # DYNAMIC\n",
    "        x_pre = x[:, :, :-1, ...]\n",
    "        \n",
    "        # out = x[:, :, 1:, ...] + x_pre\n",
    "        out[:, :, 1:, ...] = out[:, :, 1:, ...] + x_pre\n",
    "        # out = torch.cat( [x[:, :, 0, ...].unsqueeze(2), out], dim=2 )\n",
    "        \n",
    "        if add_loop:\n",
    "            out = (1 + self.eps) * x + out\n",
    "        \n",
    "        # out: [B, C, G, N, F//G]\n",
    "        out = self.mlp(out, True)\n",
    "        \n",
    "        # out: [B, C, N, F]\n",
    "        C = out.size(1)\n",
    "        out = out.transpose(2, 3).reshape(B, C, N, -1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# class Dense_TimeDiffPool2d(nn.Module):\n",
    "    \n",
    "#     def __init__(self, pre_nodes, pooled_nodes, kern_size, padding):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         # TODO: add Normalization\n",
    "#         # self.time_conv = nn.Conv2d(pre_nodes, pooled_nodes, (1, kern_size), padding=(0, padding))\n",
    "#         self.time_conv = nn.Conv2d(pre_nodes, pooled_nodes, (1, kern_size), padding=(0, padding),stride=1)\n",
    "\n",
    "        \n",
    "#         self.re_param = Parameter(Tensor(kern_size, 1))\n",
    "        \n",
    "#     def reset_parameters(self):\n",
    "#         self.time_conv.reset_parameters()\n",
    "#         init.kaiming_uniform_(self.re_param, nonlinearity='relu')\n",
    "        \n",
    "        \n",
    "#     def forward(self, x: Tensor, adj: Tensor):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             x (Tensor): [B, C, N, F]\n",
    "#             adj (Tensor): [G, N, N]\n",
    "#         \"\"\"\n",
    "#         B, G, N, F = x.size(0), adj.size(0), adj.size(1), x.size(-1)\n",
    "#         xlater = x.reshape(B, C, N, G, -1).transpose(2, 3) \n",
    "#         # print('x shape at start in diffpool', x.shape)\n",
    "#         x = x.transpose(1, 2)\n",
    "#         out = self.time_conv(x)\n",
    "#         out = out.transpose(1, 2)\n",
    "#         # print('x shape at end of time pool in diffpool', out.shape)\n",
    "        \n",
    "#         # Expand the adjacency matrix to include the batch dimension.\n",
    "#         adj_expanded = adj.unsqueeze(0).repeat(B, 1, 1, 1)  # [B, G, N, N]\n",
    "#         print('adj_expanded shape ', adj_expanded.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "#         # s: [ N^(l+1), N^l, 1, K ]     \n",
    "#         s = torch.matmul(self.time_conv.weight, self.re_param).view(out.size(-2), -1)\n",
    "#         # TODO: fully-connect, how to decrease time complexity\n",
    "#         out_adj = torch.matmul(torch.matmul(s, adj), s.transpose(0, 1))\n",
    "#         print('out adj shape in diffpool', out_adj.shape)\n",
    "\n",
    "       \n",
    "#         return out, out_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f59cfabd-01d2-437c-80c2-714ccbf0e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_TimeDiffPool2d(nn.Module):\n",
    "    \n",
    "    def __init__(self, pre_nodes, pooled_nodes, kern_size, padding):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TODO: add Normalization\n",
    "        self.time_conv = nn.Conv2d(pre_nodes, pooled_nodes, (1, kern_size), padding=(0, padding))\n",
    "        self.re_param = Parameter(Tensor(kern_size, 1))\n",
    "\n",
    "        ##added for attention in this module\n",
    "        # Adjusted attention layers for query, key \n",
    "        # Todo (and optionally value) -does it make sense\n",
    "        self.query = nn.Linear(18, 18)\n",
    "        self.key = nn.Linear(18, 18)\n",
    "\n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.time_conv.reset_parameters()\n",
    "        init.kaiming_uniform_(self.re_param, nonlinearity='relu')\n",
    "\n",
    "        ######################################## for the attention\n",
    "        init.xavier_uniform_(self.query.weight)\n",
    "        init.xavier_uniform_(self.key.weight)\n",
    "        \n",
    "        \n",
    "    def forward(self, x: Tensor, adj: Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): [B, C, N, F]\n",
    "            adj (Tensor): [G, N, N]\n",
    "        \"\"\"\n",
    "        B, C, N, F = x.shape ## added lines  # Assuming x is [B, C, N, F]\n",
    "        #################################################################\n",
    "        x = x.transpose(1, 2)\n",
    "        out = self.time_conv(x)\n",
    "        out = out.transpose(1, 2)\n",
    "\n",
    "        out_features = out\n",
    "        ##################################################################\n",
    "\n",
    "        # s: [ N^(l+1), N^l, 1, K ]\n",
    "        s = torch.matmul(self.time_conv.weight, self.re_param).view(out.size(-2), -1)\n",
    "\n",
    "        # TODO: fully-connect, how to decrease time complexity\n",
    "        out_adj = torch.matmul(torch.matmul(s, adj), s.transpose(0, 1))\n",
    "        ###################################################################\n",
    "        \n",
    "        G = adj.size(0)\n",
    "        # Reshape and transpose to include the graph dimension G\n",
    "        # xlater = out_features.reshape(B, C, self.G, N, -1).transpose(2, 3)  # [B, C, N, G, F']\n",
    "        out_features = out_features.view(B, C, N, G, -1).permute(0, 1, 3, 2, 4)  # Reshape to [B, C, G, N, F']\n",
    "        out_features_flat = out_features.reshape(B, C, G, N, -1)\n",
    "        # Apply query and key transformations\n",
    "        queries = self.query(out_features_flat)  # Shape: [B, C, G, N, pooled_nodes]\n",
    "        keys = self.key(out_features_flat)  # Shape: [B, C, G, N, pooled_nodes]\n",
    "\n",
    "        # Calculate attention scores\n",
    "        attention_scores = torch.einsum('bcgnl,bcgml->bcgnm', (queries, keys))  # [B, C, G, N, N]\n",
    "        print('att score shape before sfmax', attention_scores.shape)\n",
    "        attention_scores = softmax(attention_scores, dim=-1)  # Normalize over the last dimension\n",
    "        print('att score shape', attention_scores.shape)\n",
    "        attention_scores = torch.mean(attention_scores, dim=1)\n",
    "\n",
    "        # Combine attention_scores with the adjacency matrix\n",
    "        # Assuming adj is already [B, G, N, N]\n",
    "        adj_expanded = out_adj.unsqueeze(0).repeat(B, 1, 1, 1)\n",
    "        print('adj_expanded shape', adj_expanded.shape)\n",
    "        weighted_adj = attention_scores * adj_expanded  # Element-wise multiplication\n",
    "     \n",
    "        return out, out_adj, weighted_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "49103341-9d32-4f91-82f4-0a4c4856b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GNNStack(nn.Module):\n",
    "    \"\"\" The stack layers of GNN.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gnn_model_type, num_layers, groups, pool_ratio, kern_size, \n",
    "                 in_dim, hidden_dim, out_dim, \n",
    "                 seq_len, num_nodes, num_classes, dropout=0.5, \n",
    "                 # activation=nn.ReLU()\n",
    "                 activation=nn.SELU()\n",
    "                \n",
    "                ):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        # TODO: Sparsity Analysis\n",
    "        k_neighs = self.num_nodes = num_nodes\n",
    "        \n",
    "        self.num_graphs = groups\n",
    "        \n",
    "        self.num_feats = seq_len\n",
    "        if seq_len % groups:\n",
    "            self.num_feats += ( groups - seq_len % groups )\n",
    "        self.g_constr = multi_shallow_embedding(num_nodes, k_neighs, self.num_graphs)\n",
    "        \n",
    "        gnn_model, heads = self.build_gnn_model(gnn_model_type)\n",
    "        \n",
    "        assert num_layers >= 1, 'Error: Number of layers is invalid.'\n",
    "        assert num_layers == len(kern_size), 'Error: Number of kernel_size should equal to number of layers.'\n",
    "        paddings = [ (k - 1) // 2 for k in kern_size ]\n",
    "        \n",
    "        self.tconvs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, in_dim, (1, kern_size[0]), padding=(0, paddings[0]))] + \n",
    "            [nn.Conv2d(heads * in_dim, hidden_dim, (1, kern_size[layer+1]), padding=(0, paddings[layer+1])) for layer in range(num_layers - 2)] + \n",
    "            [nn.Conv2d(heads * hidden_dim, out_dim, (1, kern_size[-1]), padding=(0, paddings[-1]))]\n",
    "        )\n",
    "        \n",
    "        self.gconvs = nn.ModuleList(\n",
    "            [gnn_model(in_dim, heads * in_dim, groups)] + \n",
    "            [gnn_model(hidden_dim, heads * hidden_dim, groups) for _ in range(num_layers - 2)] + \n",
    "            [gnn_model(out_dim, heads * out_dim, groups)]\n",
    "        )\n",
    "        \n",
    "        self.bns = nn.ModuleList(\n",
    "            [nn.BatchNorm2d(heads * in_dim)] + \n",
    "            [nn.BatchNorm2d(heads * hidden_dim) for _ in range(num_layers - 2)] + \n",
    "            [nn.BatchNorm2d(heads * out_dim)]\n",
    "        )\n",
    "        \n",
    "        self.left_num_nodes = []\n",
    "        for layer in range(num_layers + 1):\n",
    "            left_node = round( num_nodes * (1 - (pool_ratio*layer)) )\n",
    "            if left_node > 0:\n",
    "                self.left_num_nodes.append(left_node)\n",
    "            else:\n",
    "                self.left_num_nodes.append(1)\n",
    "        self.diffpool = nn.ModuleList(\n",
    "            [Dense_TimeDiffPool2d(self.left_num_nodes[layer], self.left_num_nodes[layer+1], kern_size[layer], paddings[layer]) for layer in range(num_layers - 1)] + \n",
    "            [Dense_TimeDiffPool2d(self.left_num_nodes[-2], self.left_num_nodes[-1], kern_size[-1], paddings[-1])]\n",
    "        )\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        # self.global_pool = nn.AdaptiveAvgPool2d((1,None))\n",
    "        \n",
    "        self.linear = nn.Linear(heads * out_dim, num_classes)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        for tconv, gconv, bn, pool in zip(self.tconvs, self.gconvs, self.bns, self.diffpool):\n",
    "            tconv.reset_parameters()\n",
    "            gconv.reset_parameters()\n",
    "            bn.reset_parameters()\n",
    "            pool.reset_parameters()\n",
    "        \n",
    "        self.linear.reset_parameters()\n",
    "        \n",
    "        \n",
    "    def build_gnn_model(self, model_type):\n",
    "        if model_type == 'dyGCN2d':\n",
    "            return DenseGCNConv2d, 1\n",
    "        if model_type == 'dyGIN2d':\n",
    "            return DenseGINConv2d, 1\n",
    "        if model_type == 'dyGAT2d':\n",
    "            return DenseGATConv2d, 1\n",
    "        \n",
    "\n",
    "    # def forward(self, inputs: Tensor):\n",
    "        \n",
    "    #     if inputs.size(-1) % self.num_graphs:\n",
    "    #         pad_size = (self.num_graphs - inputs.size(-1) % self.num_graphs) / 2\n",
    "    #         x = F.pad(inputs, (int(pad_size), ceil(pad_size)), mode='constant', value=0.0)\n",
    "    #     else:\n",
    "    #         x = inputs\n",
    "            \n",
    "    #     adj = self.g_constr(x.device)\n",
    "        \n",
    "    #     for tconv, gconv, bn, pool in zip(self.tconvs, self.gconvs, self.bns, self.diffpool):\n",
    "            \n",
    "    #         x, adj = pool( gconv( tconv(x), adj ), adj )\n",
    "            \n",
    "    #         x = self.activation( bn(x) )\n",
    "            \n",
    "    #         x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "    #     # print('before pool',x.shape)\n",
    "    #     out = self.global_pool(x)\n",
    "    #     # print('after pool',out.shape)\n",
    "    #     # out = out.view(out.size(0),out.size(-1),-1)\n",
    "    #     out = out.view(out.size(0),-1)\n",
    "    #     # print('after reshape',out.shape)\n",
    "    #     out = self.linear(out)\n",
    "    #     # print('logits shape',out.shape)\n",
    "    #     # break\n",
    "    #     return out\n",
    "    def forward(self, inputs: Tensor):\n",
    "        feature_time_maps = []\n",
    "        adj_matrices = []\n",
    "    \n",
    "        if inputs.size(-1) % self.num_graphs:\n",
    "            pad_size = (self.num_graphs - inputs.size(-1) % self.num_graphs) / 2\n",
    "            x = F.pad(inputs, (int(pad_size), ceil(pad_size)), mode='constant', value=0.0)\n",
    "        else:\n",
    "            x = inputs\n",
    "        # print('x before anything',x.shape)\n",
    "        \n",
    "    \n",
    "        adj = self.g_constr(x.device)\n",
    "        # print('adj adjacency shape',adj.shape)\n",
    "        \n",
    "        layer_index = 0\n",
    "        for tconv, gconv, bn, pool in zip(self.tconvs, self.gconvs, self.bns, self.diffpool):\n",
    "            # print('x before time convolution', x.shape, 'layer_index',layer_index)\n",
    "            x = tconv(x)  # Apply time convolution\n",
    "            # print('x after time convolution', x.shape, 'layer_index',layer_index)\n",
    "            # sys.exit()\n",
    "            # print('x before graph convolution', x.shape, 'layer_index',layer_index)\n",
    "            x = gconv(x, adj)  # Apply graph convolution\n",
    "            # print('x after graph convolution', x.shape, 'layer_index',layer_index)\n",
    "            # break\n",
    "            # feature_time_maps.append(x.detach())  # Save feature representation\n",
    "            # adj_matrices.append(adj.detach())  # Save adjacency matrix after pooling\n",
    "            x, adj, awadj = pool(x, adj)  # Apply pooling, which might modify x and adj\n",
    "            # print('x after time diff pool', x.shape, 'layer_index',layer_index)\n",
    "            # print('adj after time diff pool', adj.shape, 'layer_index',layer_index)\n",
    "            # feature_time_maps.append(x.detach())  # Save feature representation\n",
    "            # adj_matrices.append(adj.detach())  # Save adjacency matrix after pooling\n",
    "    \n",
    "            x = self.activation(bn(x))\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "            layer_index += 1\n",
    "    \n",
    "        out = self.global_pool(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        # print(out.shape)\n",
    "        # sys.exit()\n",
    "    \n",
    "        return out, feature_time_maps, adj_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "bc460ff5-57e3-4a09-ae4c-96e55ae9e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'arch': 'dyGIN2d', #what other models I can put here?? dyGCN2d, dyGIN2d\n",
    "    'dataset': 'Mortality', # \"AtrialFibrillation\" # 'Mortality', # 'MIMIC3'\n",
    "    'num_layers': 2,  # the number of GNN layers  3\n",
    "    'groups': 16,  # the number of time series groups (num_graphs)\n",
    "    'pool_ratio': 0,  # the ratio of pooling for nodes\n",
    "    'kern_size': [3,3],  # list of time conv kernel size for each layer [9,5,3]\n",
    "    'in_dim': 4,  # input dimensions of GNN stacks\n",
    "    'hidden_dim': 4,  # hidden dimensions of GNN stacks\n",
    "    'out_dim': 4,  # output dimensions of GNN stacks\n",
    "    'workers': 4,  # number of data loading workers\n",
    "    'epochs': 30,  # number of total epochs to run\n",
    "    'batch_size': 4,  # mini-batch size, this is the total batch size of all GPUs\n",
    "    'val_batch_size': 4,  # validation batch size\n",
    "    'lr': 0.0001,  # initial learning rate\n",
    "    'weight_decay': 1e-4,  # weight decay\n",
    "    'evaluate': False,  # evaluate model on validation set\n",
    "    'seed': 2,  # seed for initializing training\n",
    "    'gpu': 0,  # GPU id to use\n",
    "    'use_benchmark': True,  # use benchmark\n",
    "    'tag': 'date',  # the tag for identifying the log and model files\n",
    "    'loss':'bce'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "dd15bf00-bdc0-4f5b-bd97-df23a4bef63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNStack(gnn_model_type=args['arch'], num_layers=args['num_layers'], \n",
    "                     groups=args['groups'], pool_ratio=args['pool_ratio'], kern_size=args['kern_size'], \n",
    "                     in_dim=args['in_dim'], hidden_dim=args['hidden_dim'], out_dim=args['out_dim'], \n",
    "                     seq_len=288, num_nodes=231, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "41506308-1c59-4571-8e63-646dd18d20c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNStack(\n",
       "  (g_constr): multi_shallow_embedding()\n",
       "  (tconvs): ModuleList(\n",
       "    (0): Conv2d(1, 4, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "    (1): Conv2d(4, 4, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "  )\n",
       "  (gconvs): ModuleList(\n",
       "    (0-1): 2 x DenseGINConv2d(\n",
       "      (mlp): Group_Linear(\n",
       "        (group_mlp): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), groups=16, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0-1): 2 x BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (diffpool): ModuleList(\n",
       "    (0-1): 2 x Dense_TimeDiffPool2d(\n",
       "      (time_conv): Conv2d(231, 231, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (query): Linear(in_features=18, out_features=18, bias=True)\n",
       "      (key): Linear(in_features=18, out_features=18, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (activation): SELU()\n",
       "  (softmax): Softmax(dim=-1)\n",
       "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (linear): Linear(in_features=4, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "fbadcce6-81ff-4af2-aa42-ef4674373c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make random pytorch tensor of (32, 1, 231, 288) (B, C, N, F)\n",
    "rt = torch.rand(32, 1, 231, 288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5f06bfa5-8f63-4455-97a6-59675f9b17cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att score shape before sfmax torch.Size([32, 4, 16, 231, 231])\n",
      "att score shape torch.Size([32, 4, 16, 231, 231])\n",
      "adj_expanded shape torch.Size([32, 16, 231, 231])\n",
      "att score shape before sfmax torch.Size([32, 4, 16, 231, 231])\n",
      "att score shape torch.Size([32, 4, 16, 231, 231])\n",
      "adj_expanded shape torch.Size([32, 16, 231, 231])\n"
     ]
    }
   ],
   "source": [
    "out, feature_time_maps, adj_matrices = model(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "36dea6b3-6716-4a49-8a6b-3dac11ebb6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.shape, len(feature_time_maps), len(adj_matrices)\n",
    "# (torch.Size([32, 2]), 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f649b70e-df7c-42b3-b4f6-bd34eec43775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 2]),\n",
       " torch.Size([32, 16, 231, 288]),\n",
       " torch.Size([32, 16, 208, 288]),\n",
       " torch.Size([16, 231, 231]),\n",
       " torch.Size([16, 208, 208]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, feature_time_maps[0].shape, feature_time_maps[1].shape, adj_matrices[0].shape,  adj_matrices[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5152af81-61bc-4d05-92ea-3535909175cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "231-3+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d8757990-2de8-43c5-8492-83206cacdd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_adj = torch.rand(16, 231, 231)\n",
    "temp_batched_adj = torch.rand(32, 16, 231, 231)\n",
    "temp_s = torch.rand(231, 231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f42f89d5-7e3b-4a77-8275-7ba39a1264b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_adj = torch.matmul(torch.matmul(temp_s, temp_adj), temp_s.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "449450cf-0761-4d28-be4a-ed1b692d6f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 231, 231])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5cb72b3b-4e37-4523-afa3-138a961bba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cba487a8-31a2-455f-a58c-bf57efb85aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_adj = torch.matmul(torch.matmul(temp_s, temp_batched_adj), temp_s.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d6efcc10-3c2b-4716-ad96-a82035b38c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 231, 231])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a07881-96a3-49cc-9a59-8984b32f81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "        Args:\n",
    "            x (Tensor): [B, C, N, F]\n",
    "            adj (Tensor): [B, G, N, N]\n",
    "        \"\"\"\n",
    "        adj = self.norm(adj, add_loop).unsqueeze(1)\n",
    "\n",
    "        # x: [B, C, G, N, F//G]\n",
    "        x = self.lin(x, False)\n",
    "        \n",
    "        out = torch.matmul(adj, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f40673f-bcaa-4106-a60e-4faf5f9a2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # x: [B, C, G, N, F//G]\n",
    "        x = x.reshape(B, C, N, G, -1).transpose(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7a64de34-e272-4c86-b16c-84de99c48afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtem= torch.rand(32, 16, 231, 288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8b70500d-1073-49d9-a922-3816a9204e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtem = xtem.reshape(32, 16, 231, 16, -1)\n",
    "# .transpose(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b9b5440b-7c51-48f8-81a4-a479c9b527c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 231, 16, 18])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b30dd8-92fd-41f4-9b4d-4933ec0eef04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
